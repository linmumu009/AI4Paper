from __future__ import annotations

import argparse
import json
import os
import re
import sqlite3
import sys
from datetime import datetime
from pathlib import Path
from typing import Any, Dict, List, Optional

import pandas as pd

# å‡è®¾ä½ çš„é…ç½®æ–‡ä»¶è·¯å¾„æ˜¯æ­£ç¡®çš„ï¼Œå¦‚æœæŠ¥é”™è¯·è°ƒæ•´
# sys.path.append(os.path.dirname(os.path.dirname(__file__)))
# from config.config import DATA_ROOT  # noqa: E402

# ä¸ºäº†æ–¹ä¾¿ä½ åœ¨æœ¬åœ°ç›´æ¥è¿è¡Œæµ‹è¯•ï¼Œæˆ‘å…ˆæ¨¡æ‹Ÿä¸€ä¸ª DATA_ROOTï¼Œ
# å®é™…ä½¿ç”¨æ—¶è¯·å–æ¶ˆä¸Šé¢çš„æ³¨é‡Šï¼Œåˆ æ‰ä¸‹é¢è¿™ä¸€è¡Œ
DATA_ROOT = "./data" 


# ---------------------------------------------------------------------------
# é€šç”¨å·¥å…·
# ---------------------------------------------------------------------------

def today_str() -> str:
    return datetime.now().date().isoformat()


def load_paper_assets(date_str: str) -> List[Dict[str, Any]]:
    """ä» data/paper_assets/{date_str}.jsonl åŠ è½½å…¨éƒ¨è®ºæ–‡è®°å½•ã€‚"""
    # å…¼å®¹å¤„ç†ï¼šå¦‚æœæ²¡æœ‰ä¼ æ—¥æœŸï¼Œå°è¯•è¯»å–å½“å‰ç›®å½•ä¸‹çš„æµ‹è¯•æ–‡ä»¶ï¼Œæˆ–è€…æ„å»ºè·¯å¾„
    if not date_str:
        date_str = today_str()
        
    assets_path = Path(DATA_ROOT) / "paper_assets" / f"{date_str}.jsonl"
    
    # å¦‚æœæ–‡ä»¶ä¸å­˜åœ¨ï¼Œä¸ºäº†æ¼”ç¤ºæ–¹ä¾¿ï¼Œæˆ‘è¿™é‡ŒåŠ ä¸€ä¸ª mock æ•°æ®åˆ¤å®š
    # å®é™…éƒ¨ç½²æ—¶è¯·åˆ æ‰è¿™ä¸ª if not exists çš„é€»è¾‘ï¼Œä¿ç•™ return [] å³å¯
    if not assets_path.exists():
        print(f"[PAPER_ASSETS_VIS] æ–‡ä»¶ä¸å­˜åœ¨: {assets_path} (è¯·ç¡®ä¿æœ‰æ•°æ®æ–‡ä»¶)", flush=True)
        return []

    records: List[Dict[str, Any]] = []
    with assets_path.open("r", encoding="utf-8") as f:
        for line in f:
            line = line.strip()
            if not line:
                continue
            try:
                records.append(json.loads(line))
            except json.JSONDecodeError:
                continue
    return records


def _safe_print(text: str) -> None:
    """åœ¨ Windows ç»ˆç«¯å®‰å…¨è¾“å‡ºå« Unicode çš„å­—ç¬¦ä¸²ã€‚"""
    try:
        print(text, flush=True)
    except UnicodeEncodeError:
        encoding = sys.stdout.encoding or "utf-8"
        print(text.encode(encoding, errors="replace").decode(encoding), flush=True)


def get_db_path() -> Path:
    """è¿”å› SQLite æ•°æ®åº“æ–‡ä»¶è·¯å¾„ï¼Œè‡ªåŠ¨åˆ›å»ºçˆ¶ç›®å½•ã€‚"""
    db_dir = Path(DATA_ROOT).parent / "database"
    db_dir.mkdir(parents=True, exist_ok=True)
    return db_dir / "paper_analysis.db"


# ---------------------------------------------------------------------------
# å¯è§†åŒ–å‡½æ•° 1 â€”â€” å®éªŒç»“æœæå– (ç°æœ‰åŠŸèƒ½)
# ---------------------------------------------------------------------------

def parse_results_table(paper_json: Dict[str, Any]) -> List[Dict[str, Any]]:
    """ä» blocks.results.bullets æå–ç»“æ„åŒ–å®éªŒæ•°æ®"""
    paper_id = paper_json.get("paper_id", "")
    title = paper_json.get("title", "")
    blocks = paper_json.get("blocks", {})
    if not isinstance(blocks, dict): return []
    
    results_block = blocks.get("results", {})
    bullets = results_block.get("bullets", [])
    if not isinstance(bullets, list): return []

    rows: List[Dict[str, Any]] = []

    for bullet in bullets:
        if not isinstance(bullet, str): continue

        # æ¨¡å¼ 1: "Taskï¼šMetric = Score (Â±Delta)"
        m = re.search(r"(.*?)[ï¼š:](.*?)[=â‰ˆ]\s*([\d\.]+%?)\s*\(([\+\-â†‘â†“][\d\.]+%?)", bullet)
        if m:
            rows.append({
                "Paper_ID": paper_id,
                "Title": title,
                "Task": m.group(1).strip(),
                "Metric": m.group(2).strip(),
                "Score": m.group(3).strip(),
                "Improvement": m.group(4).strip(),
            })
            continue

        # æ¨¡å¼ 2: "Taskï¼šMetric = Â±Score"
        m = re.search(r"(.*?)[ï¼š:](.*?)[=â‰ˆ]\s*([\+\-â†‘â†“][\d\.]+%?(?:\s*(?:pts|points|åˆ†))?)", bullet)
        if m:
            rows.append({
                "Paper_ID": paper_id,
                "Title": title,
                "Task": m.group(1).strip(),
                "Metric": m.group(2).strip(),
                "Score": m.group(3).strip(),
                "Improvement": m.group(3).strip(),
            })
            continue

    return rows


def visualize_results(papers: List[Dict[str, Any]]) -> pd.DataFrame:
    """ç”Ÿæˆå®éªŒç»“æœ DataFrame"""
    if not papers: return pd.DataFrame()
    all_rows = []
    for paper in papers:
        all_rows.extend(parse_results_table(paper))
    return pd.DataFrame(all_rows)


# ---------------------------------------------------------------------------
# å¯è§†åŒ–å‡½æ•° 2 â€”â€” æ–¹æ³•è®ºæå– (æ–°å¢åŠŸèƒ½)
# ---------------------------------------------------------------------------

def parse_method_row(paper_json: Dict[str, Any]) -> Dict[str, Any]:
    """
    ä» blocks.method.bullets ä¸­è§£æ ã€Keyã€‘ï¼šValue ç»“æ„ã€‚
    è¿”å›ä¸€è¡Œå­—å…¸ï¼ŒKey ä¸º 'Paper_ID', 'Title' ä»¥åŠæå–åˆ°çš„æ–¹æ³•æ ‡ç­¾ã€‚
    """
    paper_id = paper_json.get("paper_id", "")
    title = paper_json.get("title", "")
    
    # åŸºç¡€è¡Œæ•°æ®
    row = {"Paper_ID": paper_id, "Title": title}
    
    blocks = paper_json.get("blocks", {})
    if not isinstance(blocks, dict): return row
    
    method_block = blocks.get("method", {})
    bullets = method_block.get("bullets", [])
    if not isinstance(bullets, list): return row

    # æ­£åˆ™ï¼šåŒ¹é… ã€Keyã€‘ï¼šValue æˆ– ã€Keyã€‘: Value
    # å¿½ç•¥å‰å¯¼ç©ºæ ¼
    pattern = re.compile(r"^\s*ã€(.*?)ã€‘[ï¼š:]\s*(.*)$")

    for bullet in bullets:
        if not isinstance(bullet, str): continue
        match = pattern.match(bullet)
        if match:
            key = match.group(1).strip()
            val = match.group(2).strip()
            # å°†æå–åˆ°çš„ Key ç›´æ¥æ”¾å…¥ row ä¸­
            row[key] = val
        else:
            # å¦‚æœæ²¡æœ‰æŒ‰æ ¼å¼å†™ï¼Œä¹Ÿå¯ä»¥é€‰æ‹©æ”¾å…¥ "å¤‡æ³¨" å­—æ®µ
            pass
            
    return row


def visualize_methods(papers: List[Dict[str, Any]]) -> pd.DataFrame:
    """ç”Ÿæˆæ–¹æ³•è®ºå¯¹æ¯” DataFrame"""
    if not papers: return pd.DataFrame()
    
    all_rows = []
    for paper in papers:
        all_rows.append(parse_method_row(paper))
    
    df = pd.DataFrame(all_rows)
    
    # --- åˆ—æ’åºç¾åŒ– ---
    # æˆ‘ä»¬å¸Œæœ›æŸäº›é‡è¦çš„åˆ—æ’åœ¨å‰é¢ï¼Œè€Œä¸æ˜¯æŒ‰å­—æ¯é¡ºåºä¹±æ’
    priority_cols = ["Paper_ID", "Title", "æ˜¯å¦è®­ç»ƒ", "è¾“å…¥", "æ¶æ„", "å…³é”®æœºåˆ¶", "åˆ›æ–°ç‚¹"]
    
    # æ‰¾å‡º DataFrame ä¸­å®é™…å­˜åœ¨çš„åˆ—
    existing_cols = df.columns.tolist()
    
    # 1. å…ˆæ”¾ Priority ä¸­å­˜åœ¨çš„åˆ—
    final_cols = [c for c in priority_cols if c in existing_cols]
    
    # 2. å†æ”¾å‰©ä¸‹çš„åˆ—
    final_cols += [c for c in existing_cols if c not in final_cols]
    
    # --- å½’ä¸€åŒ– "æ˜¯å¦è®­ç»ƒ" åˆ— ---
    if "æ˜¯å¦è®­ç»ƒ" in df.columns:
        def _normalize_training(val: Any) -> str:
            if not isinstance(val, str) or not val.strip():
                return str(val)
            s = val.strip()
            if s.startswith("æ˜¯") or s.lower().startswith("yes"):
                return "YES"
            if s.startswith("å¦") or s.lower().startswith("no"):
                return "NO"
            return s
        df["æ˜¯å¦è®­ç»ƒ"] = df["æ˜¯å¦è®­ç»ƒ"].apply(_normalize_training)

    return df[final_cols]


# ---------------------------------------------------------------------------
# SQLite æŒä¹…åŒ–
# ---------------------------------------------------------------------------

def init_db(conn: sqlite3.Connection) -> None:
    """åˆ›å»º 3 å¼ è¡¨ï¼ˆå¦‚ä¸å­˜åœ¨ï¼‰ã€‚"""
    conn.executescript("""
        CREATE TABLE IF NOT EXISTS papers (
            paper_id   TEXT    NOT NULL,
            title      TEXT,
            url        TEXT,
            year       INTEGER,
            date       TEXT    NOT NULL,
            blocks_json TEXT,
            PRIMARY KEY (paper_id, date)
        );

        CREATE TABLE IF NOT EXISTS results (
            paper_id    TEXT NOT NULL,
            title       TEXT,
            task        TEXT,
            metric      TEXT,
            score       TEXT,
            improvement TEXT,
            date        TEXT NOT NULL,
            PRIMARY KEY (paper_id, task, metric, date)
        );

        CREATE TABLE IF NOT EXISTS methods (
            paper_id      TEXT NOT NULL,
            title         TEXT,
            is_training   TEXT,
            input         TEXT,
            architecture  TEXT,
            key_mechanism TEXT,
            innovation    TEXT,
            date          TEXT NOT NULL,
            PRIMARY KEY (paper_id, date)
        );
    """)


# æ–¹æ³•è®º DataFrame ä¸­æ–‡åˆ—å â†’ DB è‹±æ–‡åˆ—å çš„æ˜ å°„
_METHOD_COL_MAP: Dict[str, str] = {
    "Paper_ID":  "paper_id",
    "Title":     "title",
    "æ˜¯å¦è®­ç»ƒ":   "is_training",
    "è¾“å…¥":      "input",
    "æ¶æ„":      "architecture",
    "å…³é”®æœºåˆ¶":   "key_mechanism",
    "åˆ›æ–°ç‚¹":    "innovation",
}


def save_to_db(
    date_str: str,
    papers: List[Dict[str, Any]],
    df_results: pd.DataFrame,
    df_methods: pd.DataFrame,
) -> None:
    """å°†åŸå§‹è®ºæ–‡æ•°æ®ä¸åˆ†æç»“æœå†™å…¥ SQLiteï¼ˆåŒæ—¥æœŸè¦†ç›–æ¨¡å¼ï¼‰ã€‚"""
    db_path = get_db_path()
    conn = sqlite3.connect(str(db_path))
    try:
        init_db(conn)
        cur = conn.cursor()

        # ---------- 1. æ¸…é™¤è¯¥æ—¥æœŸæ—§æ•°æ® ----------
        for table in ("papers", "results", "methods"):
            cur.execute(f"DELETE FROM {table} WHERE date = ?", (date_str,))

        # ---------- 2. å†™å…¥ papers åŸºè¡¨ ----------
        for p in papers:
            cur.execute(
                "INSERT INTO papers (paper_id, title, url, year, date, blocks_json) "
                "VALUES (?, ?, ?, ?, ?, ?)",
                (
                    p.get("paper_id", ""),
                    p.get("title", ""),
                    p.get("url", ""),
                    p.get("year"),
                    date_str,
                    json.dumps(p.get("blocks", {}), ensure_ascii=False),
                ),
            )

        # ---------- 3. å†™å…¥ results è¡¨ ----------
        if not df_results.empty:
            for _, row in df_results.iterrows():
                cur.execute(
                    "INSERT INTO results "
                    "(paper_id, title, task, metric, score, improvement, date) "
                    "VALUES (?, ?, ?, ?, ?, ?, ?)",
                    (
                        row.get("Paper_ID", ""),
                        row.get("Title", ""),
                        row.get("Task", ""),
                        row.get("Metric", ""),
                        row.get("Score", ""),
                        row.get("Improvement", ""),
                        date_str,
                    ),
                )

        # ---------- 4. å†™å…¥ methods è¡¨ ----------
        if not df_methods.empty:
            for _, row in df_methods.iterrows():
                cur.execute(
                    "INSERT INTO methods "
                    "(paper_id, title, is_training, input, architecture, "
                    "key_mechanism, innovation, date) "
                    "VALUES (?, ?, ?, ?, ?, ?, ?, ?)",
                    (
                        row.get("Paper_ID", ""),
                        row.get("Title", ""),
                        row.get("æ˜¯å¦è®­ç»ƒ", ""),
                        row.get("è¾“å…¥", ""),
                        row.get("æ¶æ„", ""),
                        row.get("å…³é”®æœºåˆ¶", ""),
                        row.get("åˆ›æ–°ç‚¹", ""),
                        date_str,
                    ),
                )

        conn.commit()
        _safe_print(
            f"[PAPER_ASSETS_ANALYSIS] Saved to {db_path} "
            f"({len(papers)} papers, {len(df_results)} results, "
            f"{len(df_methods)} methods)"
        )
    finally:
        conn.close()


# ---------------------------------------------------------------------------
# CLI å…¥å£
# ---------------------------------------------------------------------------

def run() -> None:
    ap = argparse.ArgumentParser("paper_assets_analysis")
    ap.add_argument("--date", default="", help="æ—¥æœŸå­—ç¬¦ä¸²ï¼Œå¦‚ 2026-02-07ï¼›é»˜è®¤ä¸ºä»Šå¤©")
    args = ap.parse_args()

    date_str = args.date.strip() if args.date else ""
    if not date_str:
        env_date = os.environ.get("RUN_DATE", "").strip()
        date_str = env_date if env_date else today_str()

    _safe_print(f"[PAPER_ASSETS_VIS] æ—¥æœŸ={date_str}")
    
    # 1. åŠ è½½æ•°æ® (åªè¯»å–ä¸€æ¬¡)
    papers = load_paper_assets(date_str)
    if not papers:
        _safe_print("[PAPER_ASSETS_VIS] æœªæ‰¾åˆ°ä»»ä½•è®ºæ–‡æ•°æ®ã€‚")
        return

    # 2. å±•ç¤ºå®éªŒç»“æœè¡¨ (åŸæœ‰åŠŸèƒ½)
    df_results = visualize_results(papers)
    if df_results.empty:
        _safe_print("[PAPER_ASSETS_VIS] æœªæå–åˆ°å®éªŒç»“æœæ•°æ®")
    else:
        _safe_print("\n" + "="*50)
        _safe_print(" >>> ğŸ† å®éªŒç»“æœæ’è¡Œæ¦œ (Results Leaderboard)")
        _safe_print("="*50)
        pd.set_option("display.max_columns", None)
        pd.set_option("display.width", 200)
        pd.set_option("display.max_colwidth", 40)
        _safe_print(df_results.to_string(index=False))

    # 3. å±•ç¤ºæ–¹æ³•è®ºè¡¨ (æ–°å¢åŠŸèƒ½)
    df_methods = visualize_methods(papers)
    if df_methods.empty:
        _safe_print("[PAPER_ASSETS_VIS] æœªæå–åˆ°æ–¹æ³•è®ºæ•°æ®")
    else:
        _safe_print("\n" + "="*50)
        _safe_print(" >>> ğŸ› ï¸ æŠ€æœ¯æµæ´¾å…µå™¨è°± (Methodology Specs)")
        _safe_print("="*50)
        # è°ƒæ•´æ˜¾ç¤ºå®½åº¦ï¼Œå› ä¸º Method é‡Œçš„æ–‡å­—é€šå¸¸æ¯”è¾ƒé•¿
        pd.set_option("display.max_colwidth", 30) 
        _safe_print(df_methods.to_string(index=False))
        
    # 4. æŒä¹…åŒ–åˆ° SQLite
    save_to_db(date_str, papers, df_results, df_methods)

    _safe_print(f"\n[Summary] å…±åŠ è½½ {len(papers)} ç¯‡è®ºæ–‡ã€‚")


if __name__ == "__main__":
    run()