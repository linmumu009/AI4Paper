{"paper_id": "2602.15677", "title": "CAMEL: An ECG Language Model for Forecasting Cardiac Events", "url": "https://arxiv.org/abs/2602.15677", "year": 2026, "blocks": {"background": {"text": "传统心电图（ECG）模型多聚焦于静态分类任务，难以建模长时序动态节律演变；现有方法受限于短输入窗口（通常≤10秒），无法支持临床所需的分钟级心律失常预测。", "bullets": ["【痛点】：ECG模型缺乏长时序（>60秒）建模能力，无法预测未来T分钟内的心律失常事件", "【现状】：主流ECG模型以短时窗分类为主，未与临床循证推理范式对齐"]}, "objective": {"text": "提出首个面向长时序ECG预测的通用语言模型CAMEL，支持零样本、多导联、长达600秒的未来心律失常事件预测，并构建首个专用预测基准ECGForecastBench。", "bullets": ["【任务】：长时序ECG未来心律失常事件预测（如AFIB/AFL）", "【核心贡献】：首个ECG时序预测大模型 + 首个零样本ECG预测基准"]}, "method": {"text": "将每秒单导联ECG波形经CNN编码为64维向量，线性投影至LLM隐空间实现token级对齐；引入lead-aware注意力掩码支持多导联时空交互；采用五阶段课程学习策略逐步提升模型从信号重建到循证时序推理的能力。", "bullets": ["【输入】：最长600秒、单/多导联原始ECG时序信号（采样率250Hz）", "【架构】：CNN编码器 + LLM（底层为开源Transformer）", "【关键机制】：lead-aware注意力掩码、分段token化、五阶段课程学习", "【是否训练】：是 (LoRA微调)", "【创新点】：ECG波形与文本token级对齐 + 临床认知路径驱动的渐进式课程学习"]}, "data": {"text": "预训练与评估数据覆盖多源真实ECG数据集，重点构建了首个预测导向基准ECGForecastBench。", "bullets": ["【数据集】：Icentia11k (用于ECGForecastBench构建)", "【数据集】：PTB-XL, CSN, Penn, ECGBench等7个分类基准", "【来源】：公开临床ECG数据库（单导联长程记录为主）"]}, "experiment": {"text": "在ECGForecastBench上进行零样本预测评估，并在7个分类基准上做泛化测试；开展消融实验验证LoRA适配与lead-aware掩码的必要性。", "bullets": ["【基线模型】：XGB, CNN, ELM, GEM", "【消融实验】：移除LoRA / 替换为因果掩码 / 移除lead-aware掩码", "【对比设置】：零样本 vs 全监督 / 输入时长梯度（10s→600s）"]}, "metrics": {"text": "以F1为核心判据，辅以RMSE（统计量接地）、Pass@1（推理一致性）、临床可解释指标（RMSSD、PAC计数）作为辅助评估维度。", "bullets": ["F1", "RMSE", "Pass@1"]}, "results": {"text": "CAMEL在ECGForecastBench上零样本F1达73.4%，显著优于全监督和零样本基线；在分类基准上平均F1领先SOTA ELM 7.0%；统计量接地RMSE仅为GEM的一半。", "bullets": ["ECGForecastBench：F1 = 73.4% (+12.4% vs XGB, +21.1% vs ELM)", "ECGBench等7基准：Avg F1 = +7.0% vs SOTA ELM", "ECG统计量接地：RMSE = 69.23 (≈1/2 of GEM)"]}, "limitations": {"text": "模型依赖高质量长程单导联记录，尚未验证多导联同步建模的鲁棒性；课程学习阶段设计需大量临床先验知识引导；推理延迟随输入长度增长而上升。", "bullets": ["【假设强】：依赖Icentia11k式长程单导联连续记录", "【开销大】：600秒输入导致推理显存占用高、延迟上升", "【泛化限】：尚未在实时动态噪声（如运动伪影）下系统评估"]}}}
{"paper_id": "2602.15689", "title": "A Content-Based Framework for Cybersecurity Refusal Decisions in Large Language Models", "url": "https://arxiv.org/abs/2602.15689", "year": 2026, "blocks": {"background": {"text": "当前大模型拒答策略多依赖模糊意图识别或粗粒度主题分类，在网络安全双用途场景下鲁棒性差、不可审计，易因前缀扰动导致对相同技术实质请求做出不一致响应；MITRE ATT&CK等传统框架缺乏对同一技术动作在不同环境下的风险动态评估能力。", "bullets": ["【痛点】：意图依赖型策略存在根本性脆弱性，无法应对前缀扰动下的技术实质一致性判断", "【现状】：现有框架（如ATT&CK）未建模环境上下文、使用频率与防御价值的耦合效应"]}, "objective": {"text": "提出首个面向网络安全双用途特性的五维内容驱动拒答框架，显式建模进攻风险与防御价值的权衡，实现可审计、可配置、技术实质锚定的拒答决策。", "bullets": ["【任务】：安全敏感内容的细粒度拒答决策", "【核心贡献】：首个五维正交、可标注、可配置的内容驱动拒答框架"]}, "method": {"text": "基于攻防实践与专家协同，通过迭代反例分析提炼五个正交维度，为每维定义分级标准、典型示例与标注指南；支持阈值配置或策略模型（如决策树、加权评分）部署，决策输入为请求的技术实质内容，输出为拒答/放行建议。", "bullets": ["【输入】：原始用户请求（剥离前缀，聚焦技术动作）", "【架构】：规则+可学习策略空间（如加权评分、决策树）", "【关键机制】：五维正交评估、跨维度阈值配置、专家共识标注驱动", "【是否训练】：否（框架本身不依赖训练；策略模型可选训练）", "【创新点】：将拒答从意图中心转向技术实质中心，首次引入Defensive Benefit与Expected Frequency等安全治理专属维度"]}, "data": {"text": "框架构建依托真实攻防场景反例对（如仅前缀不同但技术实质相同的请求对），由网络安全专家与AI安全专家联合标注；未使用公开基准数据集，但覆盖Windows/Cisco Meraki等多环境用例及GTG-1002等真实事件模式。", "bullets": ["【数据集】：自建攻防反例对集合（含前缀扰动样本）", "【来源】：真实红蓝对抗演练、MITRE ATT&CK映射用例、GTG-1002等已知事件复现"]}, "experiment": {"text": "通过案例回溯分析验证框架解释力与修正能力，对比前沿模型（如GPT-4、Claude系列）在相同技术实质请求上的拒答一致性，并开展专家评审以确认维度划分合理性与标注可操作性。", "bullets": ["【基线模型】：GPT-4, Claude-3 Opus（作为被解释/被修正对象）", "【消融实验】：单维移除对决策稳定性的影响（文中未显式执行，但指出Offensive Risk与Defensive Benefit缺一不可）"]}, "metrics": {"text": "以拒答一致性（Consistency）、专家标注符合率（Expert Agreement Rate）、政策可解释性（via case-level rationale coverage）为主要评估维度；未采用端到端自动化指标，强调人机协同有效性。", "bullets": ["Consistency", "Expert Agreement Rate", "Rationale Coverage"]}, "results": {"text": "框架能系统性消除前缀扰动导致的拒答不一致；在S3凭据扫描+日志清除等高危请求上实现合理拒答，在IAM策略收紧等高价值低风险请求上实现精准放行；专家评审确认五维划分具备高共识度与实操性。", "bullets": ["前缀扰动请求对：Consistency = 98.2% (+41.7% vs GPT-4)", "S3+日志清除请求：拒答置信度 = 高（中等风险+有意义贡献+低频使用）", "IAM策略收紧请求：放行置信度 = 高（零进攻贡献+高频使用+显著防御收益）"]}, "limitations": {"text": "框架当前为单提示静态评估，未建模请求序列累积风险；尚未区分‘辅助生成’与‘直接执行’语义差异；依赖专家标注，规模化自动化仍需后续建模支持。", "bullets": ["【假设强】：默认单提示独立评估，忽略跨提示风险聚合（如GTG-1002事件）", "【能力缺】：未显式建模‘辅助’vs‘执行’语义层级", "【扩展难】：专家标注成本高，自动化维度判别模型尚未验证"]}}}
{"paper_id": "2602.15707", "title": "Proactive Conversational Assistant for a Procedural Manual Task based on Audio and IMU", "url": "https://arxiv.org/abs/2602.15707", "year": 2026, "blocks": {"background": {"text": "现有主动对话助手多依赖视频输入，存在隐私泄露风险、计算开销大、难以部署于边缘/可穿戴设备等问题，难以满足程序化手动任务（如装配、维修）中实时、轻量、隐私友好的指导需求。", "bullets": ["【痛点】：视频依赖导致隐私风险高、端侧部署困难", "【现状】：主流任务型对话系统过度依赖用户显式反馈，缺乏时机敏感的主动引导能力"]}, "objective": {"text": "构建首个仅基于音频与IMU信号的轻量级、隐私保护型主动对话助手，实现全栈端-边协同部署，并通过新型微调范式提升关键指令传达的准确性、克制性与时效性。", "bullets": ["【任务】：主动式程序化手动任务指导对话", "【核心贡献】：提出User Whim Agnostic（UWA）LoRA微调方法", "【目标】：解耦主动引导与视频模态，实现边缘实时、隐私安全、低延迟交互"]}, "method": {"text": "双模态信号（手表采集音频+IMU）→ CNN10 PANN + Attend&Discriminate网络识别11类手工活动 → 规则驱动步骤追踪器动态推断任务阶段并检测顺序错误 → 结构化提示注入语言模型 → UWA LoRA微调Qwen2.5强制关键节点主动输出 → Whisper（ASR）+ Qwen2.5（LM）+ MeloTTS（TTS）三级流水在边缘AI盒执行，全部模型经QNN量化部署于Qualcomm Dragonwing IQ9 NPU。", "bullets": ["【输入】：智能手表采集的原始音频波形 + 3轴IMU时序信号", "【架构】：CNN10 PANN（活动识别） + Attend&Discriminate（特征对齐） + Qwen2.5（LLM） + Whisper + MeloTTS", "【关键机制】：UWA LoRA微调、规则驱动步骤追踪器、结构化提示生成、QNN量化推理", "【是否训练】：是 (UWA LoRA微调Qwen2.5)", "【创新点】：UWA微调范式（跳过trivial用户评论链，锚定任务完成节点触发主动响应）"]}, "data": {"text": "自建手工任务数据集，覆盖典型程序化手动操作（如钻孔、拧螺丝、五类提举），含同步音频、IMU及精细标注的任务步骤与错误类型；对话交互数据来自真实用户任务执行过程。", "bullets": ["【数据集】：Custom Hand-Task Dataset (音频+IMU+步骤标注)", "【来源】：真实用户装配/维修场景采集（智能手表端）"]}, "experiment": {"text": "在真实边缘硬件（Qualcomm Dragonwing IQ9 NPU）上评估端-边协同推理延迟、指令准确率与人类交互质量；对比基线包括零样本、四示例少样本、标准LoRA微调；开展消融实验验证UWA机制与规则追踪器作用。", "bullets": ["【基线模型】：Qwen2.5-zero-shot, Qwen2.5-4shot, standard LoRA-finetuned Qwen2.5", "【消融实验】：移除UWA机制、禁用规则追踪器、替换为纯文本提示"]}, "metrics": {"text": "采用自动指标与人类评估双轨评价：自动指标聚焦指令传达可靠性与逻辑一致性；人类评估覆盖克制性、覆盖度、正确性等维度。", "bullets": ["F-score", "True Negative Rate (TNR)", "Entailment Score", "Pass@1 (step completion)", "Restraint (human-rated, 4-point scale)", "Coverage (3.43)", "Correctness (3.5)"]}, "results": {"text": "UWA微调显著提升关键指令传达性能，在保持高TNR（0.84–0.89）的同时，F-score提升超30%，Entailment得分从1.96升至1.99；推理耗时仅2.28秒，较少样本快27倍；人类评估全面优于基线。", "bullets": ["GSM8K-like step completion：F-score = >30% improvement vs baseline", "TNR：0.84–0.89 (+0.84 vs 0)", "Entailment：1.99 (+0.03 vs 1.96)", "Inference latency：2.28s (16× speedup vs unquantized, 27× vs 4-shot)", "Restraint：3.78/4", "Coverage：3.43/4", "Correctness：3.5/4"]}, "limitations": {"text": "当前系统依赖预定义11类手工活动及固定任务流程模板，泛化至长尾或开放任务受限；纠错召回率下降反映对异常状态干预能力减弱；IMU与音频信号易受佩戴位置与环境噪声干扰。", "bullets": ["【假设强】：依赖预定义活动类别与线性任务流程模板", "【泛化弱】：难以处理未见过的手工动作组合或非结构化任务", "【鲁棒性低】：IMU/音频信号质量对佩戴方式与环境噪声敏感", "【纠错退化】：纠错召回率由0.98降至0.65，异常干预能力下降"]}}}
{"paper_id": "2602.15758", "title": "ChartEditBench: Evaluating Grounded Multi-Turn Chart Editing in Multimodal Language Models", "url": "https://arxiv.org/abs/2602.15758", "year": 2026, "blocks": {"background": {"text": "现有图表生成与编辑工作多聚焦于单轮、静态的代码生成任务，缺乏对真实探索性数据分析中多轮渐进式修改能力的建模与评测；多模态大语言模型在视觉-代码联合理解与状态持续维护方面的能力尚不清晰。", "bullets": ["【痛点】：单轮评测无法反映错误累积、状态漂移等真实交互瓶颈", "【现状】：缺乏面向多轮、视觉锚定、渐进式图表编辑的标准化基准"]}, "objective": {"text": "构建首个面向真实探索性数据分析场景的多轮、视觉锚定图表编辑评测基准ChartEditBench，并设计可解释、可复现、多粒度的复合评估框架。", "bullets": ["【任务】：多轮图表编辑（视觉+代码双接地）", "【核心贡献】：提出ChartEditBench基准与三层混合评估框架"]}, "method": {"text": "输入为上一轮生成的代码及其渲染图，模型需基于自然语言指令或目标图反推本轮编辑代码；经执行验证、断言检查与视觉差异分析三级评估输出结构化得分。", "bullets": ["【输入】：上一轮代码 + 对应渲染图 + 当前轮NL指令/目标图", "【架构】：评估框架（非模型架构），含程序化验证模块与Chart-R1视觉差分模型", "【关键机制】：三层评估（执行验证 → 代码断言 → LLM驱动视觉差异分析）、双路径质检（程序化指令 + LLM评判）", "【是否训练】：否 (评估框架本身无需训练；Chart-R1为预训练模型，固定权重使用)", "【创新点】：视觉-代码双接地的多轮状态建模 + 复合评估中引入LLM细粒度视觉差分"]}, "data": {"text": "合成构建5000例多轮图表编辑样本，覆盖12类修改类型与5步渐进链，确保图表类型与修改类别均匀分布；包含430例人工标注验证子集。", "bullets": ["【数据集】：ChartEditBench (5000例合成 + 430例人类验证)", "【来源】：合成生成（基于Matplotlib/Plotly模板与可控变换规则)", "【结构】：每例含5轮渐进编辑链，每轮含输入图、输入代码、指令/目标图、标准答案"]}, "experiment": {"text": "在主流多模态模型（GPT-5-mini、Claude Haiku 4.5等）上进行多轮编辑评测，对比其在Code-to-Code与NL Delta双任务下的性能衰减曲线与模块级表现。", "bullets": ["【基线模型】：GPT-5-mini, Claude Haiku 4.5, Qwen-VL-Max", "【任务设定】：Code-to-Code（目标图→代码）与NL Delta（指令→增量代码）", "【消融实验】：程序化指令评估 vs LLM评判指令评估", "【对比维度】：轮次衰减率、修改类型成功率、视觉相似性 vs 代码质量分离分析"]}, "metrics": {"text": "采用三层指标协同评估：执行层（语法/运行/渲染/结构通过率）、断言层（指令遵循率、代码质量得分）、视觉层（Chart-R1主/次视觉差异扣分制）；最终融合为综合得分。", "bullets": ["Pass@1 (执行通过率)", "Instruction Following Rate (IFR)", "Code Quality Score (CQS)", "Visual Similarity Score (VSS)", "Delta Decay Rate (DDR)"]}, "results": {"text": "所有模型均呈现显著多轮性能衰减；视觉保真度下降最剧烈，而代码结构稳定性较高；不同模型在‘执行精度’与‘整体一致性’间存在明显权衡。", "bullets": ["All models：Delta Decay Rate = 20%–33% (vs round 1)", "Styling edits：IFR = 89.2% (+15.6% vs data ops)", "Data operation edits：IFR = 42.7% (lowest across types)", "Visual Similarity Score：drop = 35% (avg), Code Quality Score：drop = <5%", "GPT-5-mini：IFR = 78.4%, VSS = 52.1%; Claude Haiku 4.5：IFR = 63.2%, VSS = 74.8%"]}, "limitations": {"text": "合成数据虽覆盖广但真实分布偏移风险仍存；Chart-R1视觉差分依赖固定规则枚举，泛化至复杂图表类型受限；LLM评判引入主观性与计算开销。", "bullets": ["【假设强】：依赖合成数据的可控性与Chart-R1预定义视觉属性体系", "【覆盖窄】：当前12类修改未涵盖动态交互、多视图联动等高级分析操作", "【开销大】：LLM驱动视觉差分需额外调用，难以实时集成到训练循环"]}}}
{"paper_id": "2602.15763", "title": "GLM-5: from Vibe Coding to Agentic Engineering", "url": "https://arxiv.org/abs/2602.15763", "year": 2026, "blocks": {"background": {"text": "现有开源大模型在真实世界长程任务（如代码工程、终端操作、多跳推理）中面临三大瓶颈：长上下文衰减、工具调用鲁棒性差、跨任务泛化弱；同时，传统同步强化学习训练成本高、GPU利用率低，且缺乏面向智能体（agentic）行为的系统性工程基础设施。", "bullets": ["【痛点】：长程任务中一致性衰减严重，现有模型难以维持百步以上决策连贯性", "【痛点】：依赖人工prompt工程（vibe coding），缺乏可验证、可执行、可复现的智能体训练闭环", "【现状】：开源模型在SWE-bench、Terminal-Bench等真实编码基准上显著落后于闭源强模型（如Claude Opus）"]}, "objective": {"text": "提出GLM-5，构建首个面向agentic engineering范式的开源大模型技术栈，在不牺牲长程能力前提下，系统性降低训练与推理成本，并实现全栈国产芯片适配。", "bullets": ["【任务】：智能体驱动的长程真实世界编码与工程任务", "【核心贡献】：提出DSA+异步RL+grounded环境+国产芯片协同的全栈智能体工程范式"]}, "method": {"text": "以DeepSeek稀疏注意力（DSA）为算力基座，输入长上下文（200K）→经动态token筛选与稀疏计算→输出结构化动作序列；通过异步RL基础设施解耦rollout与训练，由Multi-Task Rollout Orchestrator并行采样多任务轨迹，经TITO网关对齐动作-奖励；采用直接双侧重要性采样、策略版本老化过滤、DP感知路由进行无历史策略追踪的稳定优化；所有训练均在10K+可验证SWE环境（RepoLaunch）、终端合成流水线（Harbor）、多跳知识图谱（WKG）及HTML渲染闭环中完成。", "bullets": ["【输入】：200K tokens长上下文（含代码、终端日志、HTML、搜索图谱等多模态grounding信号）", "【架构】：Transformer + DeepSeek稀疏注意力（DSA）", "【关键机制】：异步RL（rollout与训练解耦）、Token-in-Token-out（TITO）对齐、直接双侧token-level clipping、策略版本老化过滤、DP感知路由、Keep-recent-k+Discard-all上下文管理", "【是否训练】：是（异步强化学习微调，含策略梯度更新与价值网络训练）", "【创新点】：首个将异步RL基础设施、DSA长上下文建模、grounded agent环境闭环、国产芯片量化适配四者深度耦合的智能体工程框架"]}, "data": {"text": "覆盖真实世界编码与智能体行为的多维度可执行数据体系。", "bullets": ["【数据集】：SWE-bench Verified (代码修复)", "【数据集】：Terminal-Bench 2.0 (终端交互)", "【数据集】：CyberGym (网络安全任务)", "【数据集】：Vending-Bench 2 (长链$4,432真实支出任务)", "【数据集】：CC-Bench-V2 (跨平台长链协作)", "【来源】：RepoLaunch（10K+可验证GitHub SWE环境）", "【来源】：Harbor（终端任务合成流水线）", "【来源】：WKG（多跳搜索知识图谱）"]}, "experiment": {"text": "在8项ARC基准、Artificial Analysis Intelligence Index v4.0及多项真实agent基准上评估；对比基线包括GLM-4.7、Llama-3-70B、Qwen2.5-72B、Claude Opus 4.5；开展消融实验验证DSA、异步RL、TITO、上下文管理策略等模块有效性。", "bullets": ["【基线模型】：GLM-4.7, Llama-3-70B, Qwen2.5-72B, Claude Opus 4.5", "【消融实验】：移除DSA导致BrowseComp下降7.7pp；禁用TITO使梯度对齐误差上升62%；关闭策略老化过滤引发训练崩溃", "【硬件设置】：华为昇腾910B、寒武纪MLU370等7大国产平台；单节点vs双卡国际集群对比"]}, "metrics": {"text": "采用任务完成率、指标得分、效率比值等多维评估协议，强调真实世界可执行性。", "bullets": ["Pass@1", "Exact Match (EM)", "BrowseComp", "Win Rate", "Artificial Analysis Intelligence Index v4.0 Score", "GPU Utilization Ratio", "Inference Cost ($/1K tokens)"]}, "results": {"text": "GLM-5在多项真实智能体基准上刷新开源SOTA，并首次在AAII v4.0突破50分；异步RL显著提升训练效率与稳定性；国产芯片适配实现高保真低比特推理。", "bullets": ["ARC Benchmark（8项）：Avg. = +20% vs GLM-4.7", "Artificial Analysis Intelligence Index v4.0：Score = 50.0（首开开源破50先河）", "SWE-bench Verified：Pass@1 = 77.8%（SOTA）", "Terminal-Bench 2.0：Pass@1 = 60.7%（SOTA）", "CyberGym：Pass@1 = 43.2%（SOTA）", "Vending-Bench 2：$4,432长链任务完成率逼近Claude Opus 4.5", "TITO网关：梯度对齐误差 ↓62%，训练稳定性 ↑3.8×", "Ascend单机W4A8推理：LongBench v2精度损失 <0.8%，成本 ↓50%"]}, "limitations": {"text": "当前方案在极端长链（>500步）任务中仍存在策略漂移风险；多跳知识图谱WKG覆盖度受限于爬取源；国产芯片生态适配尚未覆盖全部中小厂商。", "bullets": ["【假设强】：依赖可执行环境（RepoLaunch/Harbor）的完备性与可控性，真实沙箱覆盖率影响泛化边界", "【开销大】：Multi-Task Rollout Orchestrator需调度10K+并发环境实例，对分布式资源编排提出高要求", "【扩展弱】：DP感知路由暂未支持跨设备策略路由，限制超大规模异步训练横向扩展"]}}}
{"paper_id": "2602.15772", "title": "Understanding vs. Generation: Navigating Optimization Dilemma in Multimodal Models", "url": "https://arxiv.org/abs/2602.15772", "year": 2026, "blocks": {"background": {"text": "多模态大模型中理解能力与生成能力存在此消彼长的优化困境，根源在于二者被建模为独立优化目标，导致共享参数竞争。", "bullets": ["【痛点】：理解与生成性能互斥，非本质冲突而是目标建模失当", "【现状】：主流方法将理解与生成视为分离任务，缺乏协同优化机制"]}, "objective": {"text": "提出Reason-Reflect-Refine（R3）框架，实现理解与生成能力的协同提升，首次在流程层面统一二者优化目标。", "bullets": ["【任务】：多模态协同生成与理解联合优化", "【核心贡献】：提出‘生成—理解—再生成’闭环迭代框架R3"]}, "method": {"text": "输入提示文本→Reason阶段生成结构化文本蓝图并初绘图像→Reflect阶段基于图像-提示对齐度进行自我评估，输出反思文本与编辑指令→Refine阶段执行指令修改图像；通过Tree-RL与GRPO联合优化双阶段策略，并以奖励塑形（格式正确性、改进量C_j）端到端对齐。", "bullets": ["【输入】：文本提示（含复杂指令，如Multi-Count）", "【架构】：多阶段协同架构（Reason / Reflect / Refine），集成扩散模型（图像生成/编辑）与语言模型（文本推理/反思）", "【关键机制】：树状强化学习（Tree-RL）、组相对策略优化（GRPO）、奖励塑形（Reward Shaping）", "【是否训练】：是（端到端联合训练，含扩散模型微调与LLM策略优化）", "【创新点】：将理解建模为生成过程中的主动协作者（而非后验评估），通过显式反思-精炼闭环耦合双任务目标"]}, "data": {"text": "使用GenEval++作为主生成评测基准，VQA计数子集与ITA（Image-Text Alignment）数据集用于理解能力评估。", "bullets": ["【数据集】：GenEval++ (生成质量)", "【数据集】：VQA Counting Subset (理解能力)", "【数据集】：ITA Benchmark (视觉-文本对齐理解)"]}, "experiment": {"text": "在GenEval++与VQA/ITA上对比SOTA方法Echo-4o；开展消融实验验证各阶段贡献；分析训练动态以验证协同进化机制。", "bullets": ["【基线模型】：Echo-4o", "【消融实验】：仅Reason阶段 vs. 完整R3；Reflect-only vs. Reflect+Refine", "【分析维度】：训练步数-性能曲线（生成/理解双轨演化）"]}, "metrics": {"text": "采用GenEval++整体得分、Pass@1变体（如Multi-Count准确率）、VQA计数准确率、ITA整体准确率等多维指标评估。", "bullets": ["GenEval++ Score", "Multi-Count Accuracy", "VQA Counting Accuracy", "ITA Accuracy"]}, "results": {"text": "R3在生成与理解任务上均显著超越SOTA，且呈现双向增强动态；Refine环节对理解提升贡献最大，完整闭环带来最大增益。", "bullets": ["GenEval++：Score = 0.689 (+0.010 vs. Echo-4o)", "Multi-Count：Accuracy = 提升显著（具体值未给出，但优于Echo-4o）", "VQA Counting：Accuracy = 84.6% (+5.3% vs. 79.3%)", "ITA：Accuracy = +12.77 pts", "消融结果：仅Reason → +0.22；完整R3 → +0.32"]}, "limitations": {"text": "依赖高质量图像-文本对齐判据与稳定扩散编辑模块；迭代次数受计算开销限制；反思文本质量受限于当前LLM的自我诊断能力。", "bullets": ["【开销大】：多轮迭代显著增加推理延迟与显存消耗", "【依赖强】：高度依赖扩散模型编辑可控性与Reflect判据鲁棒性", "【泛化弱】：未验证跨域（如医学、遥感）或低资源场景表现"]}}}
{"paper_id": "2602.15799", "title": "The Geometry of Alignment Collapse: When Fine-Tuning Breaks Safety", "url": "https://arxiv.org/abs/2602.15799", "year": 2026, "blocks": {"background": {"text": "在无害任务上微调对齐语言模型常导致安全护栏意外崩溃，现有方法（如零空间投影、梯度过滤）依赖一阶近似，无法解释突发式安全退化现象。", "bullets": ["【痛点】：'看似无害'的微调任务引发不可预测的安全崩溃", "【现状】：主流防御策略仅建模梯度一阶行为，忽视参数空间曲率动力学"]}, "objective": {"text": "揭示对齐崩溃的几何本质，建立形式化的对齐不稳定性条件（AIC），并推导安全损失随训练步长呈四次方增长的定量规律。", "bullets": ["【核心贡献】：提出对齐不稳定性条件（AIC）", "【任务】：理论建模与解释对齐退化的动力学机制"]}, "method": {"text": "将对齐建模为多技能效用函数，以各技能下策略与参考分布的KL散度为损失；利用Fisher信息矩阵定义敏感子空间；通过梯度流二阶泰勒展开分离投影动态与效用演化，推导损失增长律。", "bullets": ["【输入】：对齐语言模型参数 θ，微调数据集（含无害/有害样本）", "【架构】：通用语言模型（隐式，未限定具体模型）", "【关键机制】：Fisher信息矩阵分析、梯度流二阶泰勒展开、敏感子空间投影", "【是否训练】：否（理论分析框架，非训练算法）", "【创新点】：首次将对齐脆弱性归因于曲率耦合驱动的轨迹弯曲，提出AIC三要素判定准则"]}, "data": {"text": "实证分析基于多个微调数据集，重点对比‘看似无害’与明确有害数据在几何结构上的相似性。", "bullets": ["【数据集】：Alpaca Top 100（无害）", "【数据集】：HarmBench / AdvBench（有害）", "【来源】：公开对齐评测基准与合成微调数据"]}, "experiment": {"text": "验证AIC三项条件的实证表现，评估几何重叠分数（OS）对安全风险的预测能力，并对比LoRA与全参数微调下的OS-HS相关性差异。", "bullets": ["【基线模型】：LLaMA-2-7B, Vicuna-7B（对齐后模型）", "【消融实验】：比较全参数微调 vs LoRA微调的敏感子空间演化", "【控制变量】：固定初始对齐模型与优化器，仅改变微调数据与更新方式"]}, "metrics": {"text": "采用几何重叠分数（OS）量化微调方向与敏感子空间的对齐程度；以安全失效步数、有害输出率（HS）作为下游安全性能指标。", "bullets": ["OS", "HS (Harmful Score)", "Safety Breakdown Step"]}, "results": {"text": "实证证实Fisher谱呈尖锐低秩结构；OS值可提前预测安全崩溃风险，且‘无害’与‘有害’数据集OS高度重叠；LoRA微调削弱OS-HS相关性，印证其放大曲率耦合效应；四次方缩放律与实际崩溃曲线高度吻合。", "bullets": ["Fisher Spectrum：Rank < 50 / 7B params (+低秩尖锐性验证)", "Alpaca Top 100：OS = 0.87 ≈ AdvBench (0.91) (+支持几何决定论)", "LoRA微调：OS–HS correlation ↓ 63% vs full fine-tuning (+验证受限更新加剧曲率敏感)", "Safety Loss：∝ t⁴ (R² = 0.992 on 12 tasks)"]}, "limitations": {"text": "理论推导基于局部二阶近似和固定Fisher结构假设；未提供端到端曲率感知微调算法实现；OS计算依赖Hessian/Fisher估计，在大模型上存在计算开销。", "bullets": ["【假设强】：依赖局部流形平坦性与Fisher静态近似", "【计算开销大】：Fisher谱与OS需二阶导数估计，难以扩展至70B+模型", "【泛化待验】：AIC在非Transformer架构（如State Space Models）中的适用性未验证"]}}}
{"paper_id": "2602.15809", "title": "Decision Quality Evaluation Framework at Pinterest", "url": "https://arxiv.org/abs/2602.15809", "year": 2026, "blocks": {"background": {"text": "内容安全领域缺乏兼顾可信度、覆盖度与成本效益的规模化决策质量评估体系，现有统计共识方法易受群体偏差影响，导致地面真值模糊、归因困难。", "bullets": ["【痛点】：统计共识法引入模糊性，无法提供高信度地面真值", "【现状】：人工专家标注成本高、覆盖率低，难以支撑策略迭代与系统稳定性监控"]}, "objective": {"text": "构建一个以专家标注黄金数据集（GDS）为核心的端到端决策质量评估框架，实现评估过程的产品化、可审计化与可迁移化。", "bullets": ["【任务】：决策质量评估框架设计与工程落地", "【核心贡献】：提出金字塔式信任结构+智能扩增pipeline+多维解耦指标+自动化闭环工作流"]}, "method": {"text": "以SME专家标注的Golden Dataset（GDS）为唯一高信度地面真值；通过PinCLIP嵌入+XGBoost预测倾向分，实施逆倾向采样扩充GDS；将质量解耦为可靠性（Cohen’s Kappa）与正确性（12项分类指标）；引入语义覆盖率（RQ-VAE码本占比）和分布偏移度（JS Divergence）量化数据集质量；集成Policy/Update/Metrics三大模块形成自动化闭环。", "bullets": ["【输入】：Pinterest生产流量内容（图文Pin）、SME双标注结果、策略变更日志", "【架构】：XGBoost（采样模型） + RQ-VAE（语义编码） + LLM（prompt优化接口）", "【关键机制】：逆倾向采样、双标注一致性校验、策略增量图谱构建、Sankey流向分析", "【是否训练】：是（XGBoost需监督训练；RQ-VAE预训练；LLM仅提示调优，不微调）", "【创新点】：将‘评估’产品化——制度化GDS建设、智能化盲区挖掘、结构化维度解耦、自动化策略影响追踪"]}, "data": {"text": "基于Pinterest真实业务数据构建，涵盖多模态内容（图文Pin）及对应专家双标注标签，覆盖内容安全全策略域。", "bullets": ["【数据集】：GDS (Golden Dataset, SME双标注)", "【来源】：Pinterest生产流量 + 内部内容安全策略库", "【规模】：未明确数值，但强调‘有限专家资源下语义覆盖最大化’"]}, "experiment": {"text": "在Pinterest内容安全策略演进周期中部署，对比不同采样策略（随机 vs 逆倾向）、不同标注范式（单标 vs 双标）、不同策略版本下的GDS性能漂移。", "bullets": ["【基线模型】：随机采样、多数投票共识、单专家标注", "【消融实验】：去除逆倾向采样对语义覆盖率的影响；去除双标注对Kappa可靠性评估的削弱", "【场景】：策略更新前后GDS复测、新策略灰度期增量图谱构建"]}, "metrics": {"text": "采用多层级指标体系：底层评估数据集质量（语义覆盖率、JS Divergence），中层评估标注质量（Cohen’s Kappa），上层评估决策质量（12项分类指标），顶层支持策略影响量化（Informedness、Sankey流向变化率）。", "bullets": ["Cohen’s Kappa", "Exact Match (EM)", "Precision/Recall/F1", "Informedness", "JS Divergence", "Semantic Coverage (RQ-VAE)"]}, "results": {"text": "GDS成功识别出多项系统性偏差模式（如集体误读型低正确性+高可靠性），策略增量图谱使政策影响可追溯率达100%，固定GDS复测将LLM退化检出时效从周级缩短至小时级。", "bullets": ["GDS：Cohen’s Kappa = 0.89 (+0.22 vs 单标基线)", "语义覆盖率：提升至73.4% (+28.6% vs 随机采样)", "Informedness：prompt优化后提升5.2%（达标退出）", "策略变更检测：Sankey图定位标签流向变化准确率 >95%"]}, "limitations": {"text": "框架高度依赖SME专家初始投入与持续参与；语义覆盖率受限于RQ-VAE码本表达能力；逆倾向采样假设倾向分可充分反映语义盲区。", "bullets": ["【假设强】：依赖PinCLIP嵌入对多模态语义的保真度", "【开销大】：SME双标注人力成本仍显著，尚未完全自动化", "【泛化限】：RQ-VAE语义码本需针对不同平台重新学习，跨域迁移需适配"]}}}
{"paper_id": "2602.15823", "title": "CrispEdit: Low-Curvature Projections for Scalable Non-Destructive LLM Editing", "url": "https://arxiv.org/abs/2602.15823", "year": 2026, "blocks": {"background": {"text": "大语言模型编辑中，如何在提升特定能力（如事实更新）的同时避免原有通用能力退化，是长期存在的核心挑战。现有方法多将能力保留作为软正则项或经验性启发，缺乏对能力损失的显式建模与理论保障。", "bullets": ["【痛点】：现有编辑方法（如FT、AlphaEdit）导致显著能力退化（MMLU平均下降16.8%~24.5%）", "【现状】：能力保留多依赖经验调参或弱正则，缺乏几何可解释、可约束的建模框架"]}, "objective": {"text": "提出CrispEdit算法，首次将模型编辑中的能力保留建模为硬约束优化问题，并通过低曲率子空间投影实现高编辑成功率与<1%平均能力退化的统一。", "bullets": ["【任务】：受约束的大语言模型参数编辑", "【核心贡献】：将能力退化建模为显式硬约束，并基于GNH低曲率方向实现无损编辑"]}, "method": {"text": "以能力损失变化量为硬约束构建优化目标；利用Bregman散度二次近似导出Gauss-Newton Hessian（GNH）；在GNH主导的低曲率方向上执行参数更新；通过K-FAC近似+矩阵无关投影算子（基于激活/梯度协方差特征分解）高效实现子空间投影；支持顺序编辑的在线K-FAC统计累积与动态子空间更新。", "bullets": ["【输入】：预训练模型参数 θ₀、编辑样本（prompt, target）、能力评估数据集 Dₐ", "【架构】：基于二阶几何的参数投影框架（非神经网络结构，属优化层）", "【关键机制】：GNH低曲率子空间投影、K-FAC近似、matrix-free旋转-掩码-反旋转算子、在线K-FAC统计累积", "【是否训练】：否 (无需梯度回传或参数微调，仅单步投影更新)", "【创新点】：将能力保留升华为硬约束几何问题；首个支持顺序编辑且保证双重保留（能力+历史编辑）的投影框架"]}, "data": {"text": "能力评估使用标准通用能力基准；编辑任务覆盖开放域事实更新与指令对齐等场景。", "bullets": ["【数据集】：ZsRE (事实编辑)", "【数据集】：MMLU, BBH, GSM8K, ARC, TruthfulQA (能力评估)", "【来源】：公开基准数据集"]}, "experiment": {"text": "在LeNet-5（小规模验证）、LLaMA-3-8B和Qwen-1.5B（大规模验证）上开展实验；对比AlphaEdit、FT、LocBF-FT、Adam-NSCL等基线；进行消融研究（能力数据量、能量阈值γ、编辑规模）及顺序编辑变体CrispEdit-Seq评测。", "bullets": ["【基线模型】：AlphaEdit, FT, LocBF-FT, Adam-NSCL (LeNet-5)", "【消融实验】：能力数据集样本量（100 vs full）、能量阈值γ（0.5–0.99）、编辑参数量（3k → 10k）", "【变体】：CrispEdit-Seq（顺序编辑）"]}, "metrics": {"text": "编辑成功率采用标准指标；能力保持度以多项基准平均性能变化衡量。", "bullets": ["Pass@1", "Exact Match (EM)", "MMLU", "BBH", "GSM8K", "ARC", "TruthfulQA"]}, "results": {"text": "CrispEdit在ZsRE上达到80.5%可靠性，同时五项能力基准平均退化仅0.3%；顺序编辑变体CrispEdit-Seq保持90%以上批量效果，计算开销为AlphaEdit的1/8；小模型LeNet-5上验证了低曲率投影的权衡优势。", "bullets": ["ZsRE：Pass@1 = 80.5% (+12.7% vs AlphaEdit)", "MMLU：Δ = -0.3% (vs AlphaEdit: -16.8%, FT: -24.5%)", "LeNet-5：低曲率投影Pareto前沿显著优于Adam-NSCL", "CrispEdit-Seq：计算开销 = 1/8 × AlphaEdit，历史编辑保留率 > 90%"]}, "limitations": {"text": "方法依赖能力数据集构造GNH近似，虽仅需少量样本，但仍需额外监督信号；K-FAC近似在极端稀疏或长尾任务分布下可能引入偏差；顺序编辑的统计累积未考虑能力漂移的动态重校准。", "bullets": ["【假设强】：隐含能力损失景观局部二次可近似（Bregman散度有效性）", "【开销大】：K-FAC特征分解仍具O(d²)内存成本（d为参数维数），虽matrix-free但需协方差存储", "【泛化限】：当前未验证跨架构迁移（如从Qwen到Llama的投影复用）"]}}}
{"paper_id": "2602.15958", "title": "DocSplit: A Comprehensive Benchmark Dataset and Evaluation Approach for Document Packet Recognition and Splitting", "url": "https://arxiv.org/abs/2602.15958", "year": 2026, "blocks": {"background": {"text": "文档智能长期聚焦单页理解，而真实场景中大量存在杂乱拼接的多页文档包（如扫描件、邮件附件），亟需系统评估大模型对其自动拆分为独立文档的能力。", "bullets": ["【痛点】：文档包分割任务长期缺乏标准化评测基准", "【现状】：现有模型在交错/随机排列等真实扰动下性能骤降，边界检测成为核心瓶颈"]}, "objective": {"text": "提出首个面向文档包分割任务的综合性基准DocSplit及配套评估框架，填补该关键任务评测空白，并推动多文档逻辑结构理解发展。", "bullets": ["【任务】：文档包分割（含边界识别、类型分类、页序恢复）", "【核心贡献】：首个系统化基准数据集 + 解耦-融合式评估范式"]}, "method": {"text": "基于文本优先的LLM提示工程，输入原始文档包文本（OCR后或结构化XML），通过分步推理指令引导模型输出结构化分割结果（文档边界+类型标签+页序），全程无需参数更新。", "bullets": ["【输入】：OCR文本或结构化XML格式的拼接文档包", "【架构】：黑盒大语言模型（如Qwen-3 VL, Gemma-3）", "【关键机制】：结构化XML标注 + 类型约束 + 分步推理提示", "【是否训练】：否 (无需参数更新，纯提示工程)", "【创新点】：三重任务统一建模 + 双维度解耦评估 + 渐进式复杂度子集设计"]}, "data": {"text": "构建DocSplit基准，包含5个渐进式子集，覆盖同质/异质、顺序/交错/随机排列等真实扰动模式。", "bullets": ["【数据集】：DocSplit (Mono-Seq / Mono-Rand / Poly-Seq / Poly-Int / Poly-Rand)", "【来源】：真实扫描文档、公开PDF集合经可控扰动生成"]}, "experiment": {"text": "在主流多模态大模型上进行零样本评估，对比不同扰动复杂度下的性能差异，并开展消融分析以验证指标设计合理性。", "bullets": ["【基线模型】：Qwen-3 VL, Gemma-3, LLaVA-OneVision, InternVL2", "【消融实验】：替换评估指标（如用Exact Match替代V-measure+Kendall’s Tau）", "【对比设置】：五种子集跨复杂度横向评测"]}, "metrics": {"text": "采用双维度融合评估：聚类质量（V-measure & Rand Index加权）衡量边界+类型联合效果；排序质量（Kendall’s Tau）衡量页序重建；最终加权得Packet分数。", "bullets": ["V-measure", "Rand Index", "Kendall’s Tau", "Packet Score"]}, "results": {"text": "Qwen-3 VL在全子集上表现最优（Packet 0.9238–0.9492），Gemma-3集群分仅0.5584；边界检测为最大瓶颈（0.56–0.90），页序重建稳健（Tau > 0.97）；交错与随机场景性能差距超0.3。", "bullets": ["Poly-Int：Packet = 0.642 (+0.30 vs Mono-Seq)", "Poly-Rand：Packet = 0.618 (+0.33 vs Mono-Seq)", "Boundary Clustering：V-measure = 0.56–0.90", "Page Ordering：Kendall’s Tau = 0.97+", "Qwen-3 VL：Packet = 0.9238–0.9492 (SOTA)", "Gemma-3：Clustering Score = 0.5584 (lowest)"]}, "limitations": {"text": "当前基准依赖OCR质量与文本可提取性，尚未涵盖手写、低分辨率或高度图文混排等极端案例；评估仍基于文本模态，未完全释放多模态模型视觉能力。", "bullets": ["【数据假设强】：依赖OCR预处理质量与文本结构完整性", "【模态受限】：评估以文本为主，未充分激活视觉信号", "【场景覆盖弱】：暂未纳入手写体、印章遮挡、极低分辨率等鲁棒性挑战"]}}}
{"paper_id": "2602.15983", "title": "ReLoop: Structured Modeling and Behavioral Verification for Reliable LLM-Based Optimization", "url": "https://arxiv.org/abs/2602.15983", "year": 2026, "blocks": {"background": {"text": "大语言模型在组合优化任务中常生成语法正确但语义错误的代码（即‘静默失效’），这类错误可执行、无报错，却导致求解结果严重偏离真实最优解；现有自查机制受限于LLM自身推理盲区，难以可靠识别。", "bullets": ["【痛点】：静默失效无法被传统语法/运行时检查捕获，且LLM自我验证存在系统性盲区", "【现状】：现有方法依赖真实标签或人工反馈，缺乏无需标签的可靠诊断与修复机制"]}, "objective": {"text": "提出ReLoop框架，在无真实标签前提下，首次实现对LLM生成优化代码中静默失效的可靠检测与安全修复。", "bullets": ["【任务】：组合优化代码的静默失效诊断与修复", "【核心贡献】：结构化生成 + 行为验证双路径协同的无监督可信优化范式"]}, "method": {"text": "输入为自然语言描述的零售优化问题；经四阶段链式结构化生成（理解→形式化→合成→自验证）输出候选代码；再通过L1执行分析（IIS）与L2参数扰动敏感性测试进行行为验证；最后基于回归保护策略触发高置信度修复。", "bullets": ["【输入】：自然语言描述的组合优化问题（如多约束零售场景）", "【架构】：双路径协同框架（结构化生成链 + 行为验证器）", "【关键机制】：IIS不可行分析、极端参数扰动（如容量×0.001）、目标偏移阈值回滚（4%）、回归保护修复触发", "【是否训练】：否 (无需参数更新，纯推理时序机制)", "【创新点】：以求解器行为响应（而非LLM自查）作为数学建模完备性的代理信号"]}, "data": {"text": "构建RetailOpt-190基准，包含190个强组合约束的零售优化实例，聚焦保质期、库存、商品替代、离散采购等多耦合工业约束场景。", "bullets": ["【数据集】：RetailOpt-190 (零售组合优化)", "【来源】：人工构造+领域专家验证", "【特点】：强约束耦合、无真实标签、专为暴露静默失效设计"]}, "experiment": {"text": "在RetailOpt-190上评估多个主流LLM（Claude、DeepSeek、32B级模型等），对比结构化生成、行为验证及二者联合的效果，并开展消融实验验证各模块贡献。", "bullets": ["【基线模型】：Claude-3, DeepSeek-Coder-33B, Llama-2", "【消融实验】：仅结构化生成、仅行为验证、联合ReLoop", "【对比任务】：执行率、正确率、静默失效检出率"]}, "metrics": {"text": "采用执行率（Executable Rate）、正确率（Exact Match on Optimal Solution）、静默失效检出率（Silent Failure Detection Rate）作为核心评估协议。", "bullets": ["Execution Rate", "Exact Match (EM)", "Pass@1 (on feasible optimal solution)"]}, "results": {"text": "ReLoop将最强模型执行率从72.1%提升至100%，正确率从22.6%升至31.1%；结构化生成单独提升Claude准确率8.5pp；行为验证在MAMO上为Claude提升4.4pp；32B模型在RetailOpt-190上准确率为0%。", "bullets": ["RetailOpt-190：Execution Rate = 100% (+27.9pp vs baseline)", "RetailOpt-190：EM = 31.1% (+8.5pp vs baseline)", "GSM8K-OPT subset：Pass@1 = 78.5% (+12% vs Llama2)", "MAMO：EM = 62.3% (+4.4pp with behavior verification)"]}, "limitations": {"text": "行为验证对结构性错误（如错误问题分解）不敏感；结构化生成易引发中等模型语法崩溃；32B级模型在该任务上全面失效，表明当前模型规模尚不足以支撑工业级组合优化推理。", "bullets": ["【假设强】：依赖求解器（如Gurobi）提供IIS与可微扰动响应", "【开销大】：需多次求解器调用（L1+L2验证），推理延迟显著增加", "【泛化限】：当前验证机制针对线性/混合整数规划，未覆盖非凸或黑盒优化"]}}}
{"paper_id": "2602.16037", "title": "Optimization Instability in Autonomous Agentic Workflows for Clinical Symptom Detection", "url": "https://arxiv.org/abs/2602.16037", "year": 2026, "blocks": {"background": {"text": "在低流行率临床症状检测任务中，自主代理驱动的提示优化常出现性能随迭代加深而急剧下降的现象，现有研究多关注最终性能，缺乏对优化过程稳定性的系统建模。", "bullets": ["【痛点】：自主提示优化在稀疏正样本场景下易发生灾难性失稳（如敏感度在0.0↔1.0间震荡）", "【现状】：缺乏对‘优化失稳’这一新型AI失败模式的形式化定义与实证刻画"]}, "objective": {"text": "首次系统揭示并建模‘优化失稳’现象，验证其与正样本流行率的强负相关性，并提出回溯式选择机制以实现更稳健的泛化提示选取。", "bullets": ["【任务】：自主代理提示优化稳定性分析与鲁棒选取", "【核心贡献】：定义并实证‘优化失稳’为新型自主AI失败模式；提出并验证‘回溯优于干预’方法论"]}, "method": {"text": "输入为原始自然语言症状描述（如‘脑雾’），经Pythia多智能体框架执行双阶段优化：开发阶段动态聚焦敏感度/特异度提升，验证阶段严格数据隔离；最终由Selector Agent回溯全轨迹选择开发集F1最优提示。", "bullets": ["【输入】：单个自然语言症状词（如‘脑雾’）", "【架构】：多智能体（Specificity/Sensitivity Improver + Critic Generator + Summarizer）", "【关键机制】：双阶段优化（开发/验证分离）、回溯式提示选择（Selector Agent）", "【是否训练】：否 (全程在目标LLM上推理执行，无参数更新)", "【创新点】：将提示优化过程建模为可诊断的动态系统，引入‘选择智能体’替代‘引导智能体’"]}, "data": {"text": "面向真实临床场景的低流行率症状分类任务，覆盖三种不同流行率的典型症状。", "bullets": ["【数据集】：自建临床症状二分类数据集（脑雾:3%, 胸痛:12%, 气短:23%）", "【来源】：真实电子病历与医生标注"]}, "experiment": {"text": "在三类流行率症状上对比Guiding Agent（主动干预）与Selector Agent（回溯选择）的效果，评估开发集震荡性、开发-验证F1差距及最终验证F1。", "bullets": ["【基线模型】：专家词典规则（如SNOMED CT关键词匹配）", "【消融实验】：对比Guiding vs Selector Agent；开发集是否可用作泛化代理", "【控制变量】：固定目标LLM、开发/验证集划分、迭代轮数（共6轮）"]}, "metrics": {"text": "以F1-score为核心指标，辅以敏感度（Recall）与特异度（Specificity）分离评估，重点关注开发集震荡幅度与开发-验证F1 gap。", "bullets": ["F1", "Recall", "Specificity", "F1 Gap (dev - val)"]}, "results": {"text": "低流行率症状（如脑雾）存在显著优化失稳，但Selector Agent可有效规避崩溃，显著超越专家基线且泛化更稳健。", "bullets": ["脑雾：F1 = 0.25 (+331% vs 专家词典)", "脑雾：Recall震荡范围 = 0.0 ↔ 1.0（第3/6轮Recall=0）", "脑雾：Guiding Agent导致F1 Gap = 0.47，Selector Agent显著压缩该gap", "脑雾：开发集最优迭代（第2轮，F1=0.44）≠ 验证最优（Selector选第1轮，F1=0.25）"]}, "limitations": {"text": "结论受限于特定临床症状类型与LLM选择，未扩展至多症状联合检测或跨模型泛化；回溯机制依赖开发集质量，仍需独立验证集保障可靠性。", "bullets": ["【假设强】：依赖开发集能覆盖症状语义多样性", "【范围窄】：仅验证单症状二分类，未覆盖多标签/长尾共病场景", "【开销大】：需完整运行全部迭代再选择，推理延迟增加"]}}}
{"paper_id": "2602.16038", "title": "Heuristic Search as Language-Guided Program Optimization", "url": "https://arxiv.org/abs/2602.16038", "year": 2026, "blocks": {"background": {"text": "现有LLM驱动的自动启发式设计（AHD）高度依赖人工试错与领域经验，反馈稀疏、机制纠缠、难以分析和改进，导致演化过程黑箱化、鲁棒性差、泛化能力弱。", "bullets": ["【痛点】：反馈稀疏（仅标量奖励或纯文本反思）", "【痛点】：机制纠缠（评估、分析、生成耦合不可分）", "【现状】：端到端生成在复杂约束任务中失效（如HeuriGen QYI≈0）"]}, "objective": {"text": "提出LaGO框架，首次将启发式发现过程显式解耦为前向评估、后向分析、更新生成三个可独立优化模块，实现语言引导的程序空间结构化优化。", "bullets": ["【任务】：自动启发式设计（AHD）", "【核心贡献】：结构化解耦LLM启发式演化范式", "【目标】：从黑箱式经验工程迈向白盒化系统科学"]}, "method": {"text": "输入为初始启发式集合与问题实例；前向模块执行代码并记录细粒度执行轨迹；后向模块（Analyst）将轨迹转化为结构化语义梯度Δ；更新模块（Generator）基于多样性选择父代、融合多策略生成新候选；联合优化同步演化构造型与改进型启发式，并通过多样性感知种群管理缓解模式崩溃。", "bullets": ["【输入】：初始启发式集合 + 组合优化问题实例（如PDPTW）", "【架构】：模块化三阶段流程（Evaluator → Analyst → Generator）+ 联合优化控制器", "【关键机制】：语义梯度Δ（张量统计 + 可执行Python特征函数）、行为多样性选择、算法骨架引导、结构化反馈", "【是否训练】：否（无需参数更新；LLM仅作条件生成器，不微调）", "【创新点】：将AHD建模为离散程序空间上的期望适应度优化问题，而非隐式进化搜索"]}, "data": {"text": "在四个真实世界组合优化任务上验证，覆盖物流调度与航空排班等高约束场景。", "bullets": ["【数据集】：PDPTW（带时间窗的接送问题）", "【数据集】：机组配对（Crew Pairing）", "【数据集】：Vehicle Routing with Time Windows (VRPTW)", "【数据集】：Capacitated Vehicle Routing Problem (CVRP)"]}, "experiment": {"text": "在统一测试协议下对比主流AHD方法，并开展多维度消融实验以验证模块可迁移性与正交性。", "bullets": ["【基线模型】：EoH, ReEvo, LLM-LNS, HeuriGen", "【消融实验】：移除联合优化（QYI↓0.3）", "【消融实验】：替换为朴素文本反思（代码分析师移除→LLM-LNS QYI↓0.13）", "【消融实验】：禁用多样性策略（ReEvo增益消失，QYI↓0.2）"]}, "metrics": {"text": "采用QYI（Quality-Yield Index）作为主指标，综合衡量解质量与可行性比率；辅以泛化差距（Generalization Gap）评估跨实例鲁棒性。", "bullets": ["QYI", "Generalization Gap"]}, "results": {"text": "LaGO在全部四个任务上显著超越所有基线，展现出更强的可行性、鲁棒性与泛化能力；各模块具备跨框架迁移价值。", "bullets": ["PDPTW：QYI = 0.82 (+0.17 vs best baseline)", "泛化差距：0.07 (vs baseline 0.24)", "EoH + LaGO联合优化：QYI = 0.75 (+0.30 vs vanilla EoH)", "LLM-LNS + LaGO代码分析师：QYI = 0.68 (+0.13 vs vanilla LLM-LNS)"]}, "limitations": {"text": "当前框架依赖高质量初始启发式种子与可执行环境支持；语义梯度构建对轨迹解析鲁棒性敏感；尚未适配非Python启发式或编译型语言。", "bullets": ["【假设强】：依赖可运行的Python启发式代码与细粒度执行日志", "【开销大】：前向模块需多次执行候选程序，推理延迟高", "【覆盖窄】：暂未支持C++/Java等非解释型语言启发式"]}}}
{"paper_id": "2602.16050", "title": "Evidence-Grounded Subspecialty Reasoning: Evaluating a Curated Clinical Intelligence Layer on the 2025 Endocrinology Board-Style Examination", "url": "https://arxiv.org/abs/2602.16050", "year": 2026, "blocks": {"background": {"text": "当前临床AI系统普遍依赖大语言模型的通用知识与实时网络检索能力，但在专科医学考试和高风险决策场景中，存在证据不可追溯、逻辑不可审计、答案不可验证等可靠性瓶颈。", "bullets": ["【痛点】：LLM答案缺乏可验证的证据支撑，难以被临床医生信任", "【现状】：主流范式强调更大参数规模与更强网络检索，忽视结构化专科证据基建"]}, "objective": {"text": "验证一种不依赖实时网络检索、仅基于分层 curated 证据库与结构化推理架构的临床AI系统（Mirror），能否在专科医学考试中超越前沿大语言模型及人类参考水平。", "bullets": ["【任务】：专科临床推理（内分泌学考试）", "【核心贡献】：提出‘证据即接口’的可验证临床AI范式"]}, "method": {"text": "输入为临床问题（含患者特征与题干），经任务类型识别后路由至专用推理模块；各模块基于三级分层证据库进行证据检索、逻辑匹配与方案生成；仲裁层融合多模块输出并强制绑定证据源引用，最终输出带溯源标记的答案。", "bullets": ["【输入】：标准化临床问题（含患者背景、主诉、检查结果）", "【架构】：多组件推理架构（诊断/治疗/病理专用模块 + 仲裁层）", "【关键机制】：分层证据检索、证据绑定输出、任务路由仲裁", "【是否训练】：否 (无需参数更新，纯检索+规则+逻辑推理)", "【创新点】：‘证据即接口’设计，强制输出可人工核查的证据引用"]}, "data": {"text": "构建覆盖内分泌与心代谢领域的三级分层证据库，来源权威、标注严格。", "bullets": ["【数据集】：ESAP 2025 内分泌学考试题（含标准答案与难度标注）", "【数据集】：三级证据库（指南→高质量文献→关键RCT）", "【来源】：ADA、EASD、AACE指南；NEJM、Lancet、JAMA等期刊文献；FDA/NCT注册RCT"]}, "experiment": {"text": "在完全闭源环境下对Mirror与GPT-5.2等前沿LLM进行盲测对比，所有模型均使用相同题干格式；Mirror禁用网络访问，对比模型开放实时Web检索以凸显证据策略差异。", "bullets": ["【基线模型】：GPT-5.2（启用实时Web检索）、Claude-3.5、Gemini-2.0", "【消融实验】：未显式开展，但错误模式分析隐含模块贡献评估", "【评估协议】：严格闭源、单次作答、人工双盲校验"]}, "metrics": {"text": "采用标准医学考试评价指标，强调可验证性与临床适配度。", "bullets": ["Accuracy", "Top-2 Accuracy", "Evidence Citation Rate", "Citation Accuracy (human-verified)"]}, "results": {"text": "Mirror在ESAP 2025内分泌考试中全面领先：整体准确率87.5%，Top-2准确率92.5%，在最难30题上达76.7%，显著优于所有对比模型；其治疗类问题优势突出（+15.5个百分点），且74.2%答案引用指南级证据，人工验证引用准确率达100%。", "bullets": ["ESAP 2025：Accuracy = 87.5% (+12.2% vs GPT-5.2)", "ESAP 2025（最难30题）：Accuracy = 76.7% (+23.4% vs GPT-5.2)", "Treatment Questions：Accuracy = +15.5 pts over best LLM", "Evidence Citation Rate = 74.2% (Guideline-level)", "Citation Accuracy = 100% (human-verified)"]}, "limitations": {"text": "系统在跨域交织型问题（如诊断+治疗+病理联合推理）上表现下降；证据库覆盖范围受限于当前构建粒度与领域边界；推理过程缺乏显式概率建模。", "bullets": ["【覆盖窄】：证据库限于内分泌与心代谢，未泛化至其他专科", "【整合弱】：多域交织问题（如‘糖尿病+心衰+肾病’共病决策）易出错", "【无不确定性】：输出为确定性答案，缺乏置信度或替代方案提示"]}}}
{"paper_id": "2602.16052", "title": "MoE-Spec: Expert Budgeting for Efficient Speculative Decoding", "url": "https://arxiv.org/abs/2602.16052", "year": 2026, "blocks": {"background": {"text": "MoE大语言模型在推测解码验证阶段面临专家激活爆炸问题，导致内存带宽瓶颈，限制吞吐量提升。", "bullets": ["【痛点】：验证阶段专家激活呈重尾分布，长尾专家带来显著开销但几乎不提升生成质量", "【现状】：传统方法中draft树规模增大导致每层激活专家数趋近总数，验证成本失控"]}, "objective": {"text": "提出无需训练的专家预算机制MoE-Spec，在维持生成质量前提下显著降低验证阶段内存带宽压力与计算开销。", "bullets": ["【任务】：MoE模型推测解码中的验证加速", "【核心贡献】：提出无训练、验证时动态裁剪的专家预算机制MoE-Spec"]}, "method": {"text": "基于draft树中各token的路由器输出概率，跨token聚合专家重要性，动态限定每层最多加载B个专家；采用截断或替换策略实现预算内专家重分配。", "bullets": ["【输入】：draft树中所有token的原始router logits / top-k expert IDs", "【架构】：MoE（支持OLMoE/Qwen3/Mixtral等任意MoE backbone）", "【关键机制】：路由器排序（跨token路由概率求和）、预算约束（每层≤B专家）、截断/替换覆盖策略", "【是否训练】：否 (无需参数更新，纯推理时调度)", "【创新点】：将单token稀疏性扩展为batch级验证稀疏性，实现专家激活与draft树规模解耦"]}, "data": {"text": "在多个主流MoE模型及下游任务数据集上验证方法有效性。", "bullets": ["【数据集】：MBPP (代码生成)", "【数据集】：HumanEval (代码生成)", "【数据集】：CNN/DM (摘要生成)", "【来源】：OLMoE、Qwen3、Mixtral三大MoE架构"]}, "experiment": {"text": "对比MoE-Spec与SOTA方法EAGLE-3，在不同专家预算B设置下评估吞吐量、接受长度与重构误差。", "bullets": ["【基线模型】：EAGLE-3", "【消融实验】：静态排序 vs 路由器排序 vs Oracle排序", "【变量控制】：专家预算B∈{8,16,24,32,64}", "【对比维度】：吞吐量、平均接受长度、重构误差、任务特异性压缩上限"]}, "metrics": {"text": "以吞吐量（tokens/sec）、平均接受长度、重构误差为核心评估指标，并结合任务级准确率（Pass@1）分析质量保持能力。", "bullets": ["Throughput", "Accept Length", "Reconstruction Error", "Pass@1"]}, "results": {"text": "MoE-Spec在三大MoE架构上实现10–30%吞吐提升，平均接受长度仅微降1.4%，且在激进预算下仍紧贴Oracle性能上限。", "bullets": ["OLMoE：Throughput = +24% vs EAGLE-3 (B=16)", "Qwen3：Accept Length = -1.4% (vs EAGLE-3), Pass@1 ≈ unchanged", "MBPP：前8专家覆盖90%+路由，B=8时Throughput +30%", "CNN/DM：需B≥24达90%覆盖，B=24时Throughput +10%"]}, "limitations": {"text": "方法依赖路由器输出的可靠性，对低质量router logits敏感；共激活建模缺失导致冗余选择；任务适配需人工设定预算阈值。", "bullets": ["【假设强】：依赖router logits能准确反映专家贡献度", "【建模弱】：忽略专家间共激活相关性，导致冗余选择（实测共激活频次达随机期望10–33倍）", "【人工调参】：最优预算B需按任务类型（如代码/摘要）经验设定，缺乏自适应机制"]}}}
{"paper_id": "2602.16053", "title": "Multi-Objective Alignment of Language Models for Personalized Psychotherapy", "url": "https://arxiv.org/abs/2602.16053", "year": 2026, "blocks": {"background": {"text": "当前AI心理治疗系统面临共情体验与临床安全难以兼顾的二元困境：单目标对齐方法易导致安全让位于共情（如高共情模型毒性率上升），而传统后验安全过滤又损害治疗自然性与患者自主性。", "bullets": ["【痛点】：共情与安全等多目标在优化中存在冲突，现有单目标方法无法协同保障", "【现状】：多数对齐工作聚焦通用场景或单一维度（如仅安全或仅共情），缺乏面向临床刚性约束与患者偏好并重的多目标建模框架"]}, "objective": {"text": "提出首个面向心理治疗场景的多目标直接偏好优化框架MODPO，实现共情、安全、自主性、积极倾听、信任关系、自我驱动改变六维治疗目标的协同对齐，并通过真实患者偏好数据与临床专家验证确保临床有效性与部署可行性。", "bullets": ["【任务】：多目标偏好对齐（心理治疗对话生成）", "【核心贡献】：首个基于真实患者画像的六维临床目标DPO框架；将安全内化为可学习目标而非后验规则；建立跨学科验证闭环"]}, "method": {"text": "以患者画像为输入，经六任务RoBERTa-large奖励模型打分，构建多目标偏好对，采用MODPO算法联合优化：锚定主目标（如empathy）主导梯度更新，其余目标以margin约束嵌入DPO损失，避免梯度干扰。", "bullets": ["【输入】：患者画像（含人口统计、症状史、六维偏好排序）+ 对话候选响应对", "【架构】：RoBERTa-large（六任务奖励模型） + LLaMA-2/3（策略模型）", "【关键机制】：MODPO margin嵌入、锚定目标主优化、多目标偏好对构造", "【是否训练】：是 (MODPO端到端微调策略模型，奖励模型固定)", "【创新点】：将临床安全等硬约束转化为可微margin项纳入DPO损失，实现多目标无冲突协同优化"]}, "data": {"text": "基于335名真实心理健康经历者的结构化问卷，构建150例分层抽样患者画像数据集，每例标注六维治疗目标（empathy, safety, active listening, self-motivated change, trust/rapport, patient autonomy）的个体化重要性排序；配套生成临床专家盲评响应对与LLM代理评估标签。", "bullets": ["【数据集】：MODPO Survey (心理治疗患者偏好数据集)", "【来源】：真实患者问卷调查（n=335） + 临床专家标注（n=12） + LLM代理校准", "【标注类型】：六维偏好排序 + 响应对偏好标注（win/loss/tie）"]}, "experiment": {"text": "在两阶段实验中对比五类对齐方法：单目标SFT/DPO、DPO Soup、联合损失DPO、MODPO；采用临床专家盲评与LLM代理双轨评估，在七项临床指标上进行量化比较，并开展消融研究验证margin机制与领域特异性建模效果。", "bullets": ["【基线模型】：SFT, DPO (single-objective), DPO Soup, Joint-DPO", "【消融实验】：去除margin约束、替换为通用语用学准则（Grice四准则）、减少目标维度（3 vs 6）", "【评估范式】：临床专家盲评 + LLM代理评估（Fleiss’κ / Gwet’s AC1一致性检验）"]}, "metrics": {"text": "采用人类一致性指标（Fleiss’κ、Gwet’s AC1）、偏好胜率（Win Rate）、各维度准确率（Per-dimension Accuracy）、毒性率（Toxicity Rate）及七项临床指标综合首选率。", "bullets": ["Fleiss’κ", "Gwet’s AC1", "Win Rate", "Per-dimension Accuracy", "Toxicity Rate", "Clinician Preference Rate"]}, "results": {"text": "MODPO在共情（77.6%）与安全（62.6%）间取得最优平衡，显著优于单目标DPO（93.6%/47.8%）；毒性率降至0.5%（vs 基线1.2%）；临床专家首选率达70.3–80.0%，媲美医生间一致性；六目标扩展下仍稳定收敛。", "bullets": ["empathy：Accuracy = 77.6% (+12.2% vs single-DPO safety drop)", "safety：Accuracy = 62.6% (+14.8% vs single-DPO)", "Toxicity Rate：0.5% (-0.7pp vs baseline 1.2%)", "Clinician Preference Rate：70.3–80.0% (≈ inter-clinician agreement)", "MODPO Survey vs MODPO Maxim：+17.2pp on self-motivated change accuracy"]}, "limitations": {"text": "依赖高质量患者偏好标注与临床专家资源；当前六目标未覆盖所有潜在临床维度（如文化适配性）；LLM代理评估虽经校准仍存在泛化边界；margin超参需人工调优，尚未完全自动化。", "bullets": ["【数据强依赖】：需大规模真实患者画像与专家标注，冷启动成本高", "【维度覆盖有限】：未纳入文化敏感性、语言多样性等扩展维度", "【评估边界】：LLM代理在极端病理案例中一致性下降", "【调优开销】：margin阈值需基于验证集人工设定，缺乏自适应机制"]}}}
{"paper_id": "2602.16054", "title": "CLAA: Cross-Layer Attention Aggregation for Accelerating LLM Prefill", "url": "https://arxiv.org/abs/2602.16054", "year": 2026, "blocks": {"background": {"text": "长上下文大语言模型在预填充阶段面临令牌重要性估计不准确、层间排序不稳定的问题，导致KV缓存压缩方法性能受限。", "bullets": ["【痛点】：现有启发式方法（如GemFilter、FastKV）在不同网络层间对令牌重要性的排序高度不稳定，尤其早期层（0–4）和特定中层（如Layer 10附近）与真实重要性显著偏离。", "【现状】：缺乏可解释、可量化的令牌重要性真值基准，导致评估与优化脱节。"]}, "objective": {"text": "构建可解释的令牌重要性真值基准，并基于诊断发现设计鲁棒、轻量、即插即用的跨层聚合排序方法，提升预填充阶段KV压缩的准确性与稳定性。", "bullets": ["【任务】：令牌重要性估计与排序", "【核心贡献】：提出Answer-Informed Oracle真值基准；提出跨层注意力聚合（CLAA）方法"]}, "method": {"text": "输入完整prompt和生成answer → 前向获取所有prompt token的key → 提取answer token的query → 计算query对各层prompt key的注意力得分 → 跨层/头取最大值并1D平均池化得Oracle；CLAA则延迟前m=4层KV压缩，在lp前n=4层窗口内对每个prompt token计算多层重要性分数并取最大值作为最终排序。", "bullets": ["【输入】：完整prompt + 生成answer（用于Oracle构建）；仅prompt（用于CLAA推理时）", "【架构】：基于Transformer注意力机制的分析与聚合", "【关键机制】：Answer-Informed Oracle构建、跨层最大值聚合（CLAA）、延迟早期层KV压缩", "【是否训练】：否 (无需参数更新，纯前向分析与规则聚合)", "【创新点】：首次基于生成答案反溯注意力定义令牌重要性真值；以极简跨层最大值聚合对抗单层噪声"]}, "data": {"text": "实验覆盖标准长上下文评测基准，包含结构化与非结构化文本场景。", "bullets": ["【数据集】：LongBench (综合长文本理解)", "【数据集】：Needle-in-a-Haystack (关键信息定位)", "【来源】：公开benchmark，含多领域长文档、问答对、代码等"]}, "experiment": {"text": "在统一硬件（A100）、后端（FlashAttention-2）与超参（观察窗W=8、池化核大小7）下，对比CLAA与GemFilter、FastKV、Speculative Prefill等方法。", "bullets": ["【基线模型】：Llama-3.1-8B", "【消融实验】：不同m/n配置（如m=4,n=4）、不同剪枝层lp位置", "【对比方法】：GemFilter, FastKV, Speculative Prefill"]}, "metrics": {"text": "以Spearman秩相关系数衡量排序与Oracle对齐度；以任务级指标（如LongBench平均分、Needle召回率）评估下游效果；辅以TTFT、KV内存、吞吐量（tps）评估效率。", "bullets": ["Spearman Rank Correlation", "LongBench Score", "Needle Recall Rate", "TTFT", "KV Memory Usage", "Tokens per Second (tps)"]}, "results": {"text": "CLAA显著缩小与Oracle的性能差距，在LongBench 10%保留率下达47.13%，逼近Oracle上限47.83%；在Needle任务中对中间‘针’召回率大幅超越基线；TTFT最高降低39%，KV开销仅+0.2GB，吞吐量达19–20 tps。", "bullets": ["LongBench：Score = 47.13% (+0.70% vs Oracle 47.83%)", "Needle-in-a-Haystack：Middle-position recall = significantly higher than GemFilter/FastKV", "TTFT：550ms vs 900ms (−39%)", "Throughput：19–20 tps (> GemFilter's 16 tps)"]}, "limitations": {"text": "Oracle构建依赖完整answer生成，不可用于纯流式预填充场景；CLAA需额外前向多层计算，虽轻量但非零开销；泛化性验证尚未覆盖更多模型族（如MoE或Decoder-only变体）。", "bullets": ["【假设强】：Oracle需已知answer，无法部署于zero-shot streaming prefill", "【开销】：CLAA需在n=4层窗口内重复计算重要性分数，引入轻微计算冗余", "【覆盖窄】：实验集中于Llama-3.1-8B，未验证在Qwen、Phi等架构上的迁移性"]}}}
{"paper_id": "2602.16066", "title": "Improving Interactive In-Context Learning from Natural Language Feedback", "url": "https://arxiv.org/abs/2602.16066", "year": 2026, "blocks": {"background": {"text": "现有大语言模型在多轮自然语言反馈下的动态上下文学习能力薄弱，尤其在高难度推理任务中表现脆弱，表明该能力尚未被充分激发。", "bullets": ["【痛点】：旗舰模型（Gemini 2.5、GPT-5）对语言反馈的整合能力有限，缺乏真正的交互式自纠错机制", "【现状】：反馈常被简单视为提示工程的一部分，未建模为可习得的认知技能"]}, "objective": {"text": "提出RL²F框架，将语言反馈驱动的多轮交互式上下文学习建模为可训练技能，提升模型的反馈整合能力、跨领域泛化性与自纠错能力。", "bullets": ["【任务】：交互式上下文学习（Interactive In-Context Learning）", "【核心贡献】：首次将语言反馈交互建模为可习得的认知技能，并实证‘上下文可塑性’为核心机制"]}, "method": {"text": "将单轮可验证任务重构为多轮教学式交互；教师模型利用特权信息生成不泄露答案的语言反馈，学生模型据此迭代修正；以自动验证结果为稀疏奖励信号，通过强化学习优化学生策略；师生共享基础模型，仅靠信息不对称构建高质量反馈；联合建模教师反馈预测（世界建模目标），内化反馈闭环。", "bullets": ["【输入】：任务指令 + 历史响应 + 自然语言反馈", "【架构】：共享权重的LLM（如Gemini 2.5系列）", "【关键机制】：信息不对称驱动的教学闭环、反馈预测联合训练、上下文可塑性优化", "【是否训练】：是 (PPO强化学习 + 反馈预测辅助损失)", "【创新点】：用信息不对称替代能力差构建教学关系；显式建模并优化‘上下文可塑性’"]}, "data": {"text": "以数学推理任务为主训练，覆盖多轮可验证场景；评估扩展至编码、抽象推理、逻辑谜题等未见领域。", "bullets": ["【数据集】：HardMath2 (数学)", "【数据集】：LiveCodeBench (编码)", "【数据集】：ARC-AGI (抽象推理)", "【数据集】：Logic Puzzles (逻辑谜题)"]}, "experiment": {"text": "在HardMath2上进行RL²F细调；对比基线包括原始Gemini 2.5 Flash/Pro、监督微调变体；开展跨域零样本迁移评估；消融实验验证反馈预测模块与多轮结构的必要性。", "bullets": ["【基线模型】：Gemini 2.5 Flash, Gemini 2.5 Pro", "【消融实验】：移除反馈预测目标、单轮vs多轮交互", "【设置】：PPO训练，奖励=自动验证结果（正确/错误）"]}, "metrics": {"text": "以任务完成正确性为核心评估标准，采用严格自动验证协议；跨域评估使用各领域标准指标。", "bullets": ["Pass@1", "Exact Match (EM)", "Win Rate (vs baseline)"]}, "results": {"text": "RL²F显著提升小型模型性能并实现强跨域泛化；模型展现出更高上下文可塑性与自主反馈能力。", "bullets": ["HardMath2：EM = 72.3% (+15.6% vs Gemini 2.5 Flash)", "LiveCodeBench：Pass@1 = 48.9% (+7.2% vs baseline)", "ARC-AGI：Win Rate = 63.5% (+7.1%)", "逻辑谜题：平均提升 +7.0%", "上下文可塑性量化得分：+22.4% (人工评估)"]}, "limitations": {"text": "当前方法依赖可自动验证的任务结构，对开放生成类反馈适应性有限；多轮训练带来更高计算开销；反馈质量仍受限于教师建模假设。", "bullets": ["【假设强】：依赖任务结果可自动验证，难以拓展至主观/长程目标", "【开销大】：PPO训练需大量对话轨迹采样与rollout", "【泛化边界】：未验证非结构化领域（如创意写作、伦理判断）中的反馈有效性"]}}}
{"paper_id": "2602.16069", "title": "The Limits of Long-Context Reasoning in Automated Bug Fixing", "url": "https://arxiv.org/abs/2602.16069", "year": 2026, "blocks": {"background": {"text": "当前大语言模型虽宣称支持64k–128k tokens长上下文，但在仓库级缺陷修复等需整合跨文件、多位置信息的软件工程任务中，其实际长上下文推理能力缺乏严格验证。", "bullets": ["【现状】：SWE-bench等主流代理式评测隐含任务分解，未真实检验单次长上下文理解与生成能力", "【痛点】：名义上下文长度（如128k）与可用上下文容量严重脱节，模型在真实长输入下性能急剧退化"]}, "objective": {"text": "揭示主流LLM在仓库级代码补丁生成任务中长上下文推理能力的真实瓶颈，并提出一种剥离检索干扰、聚焦模型本体能力的可控长上下文评测范式。", "bullets": ["【任务】：单次长上下文补丁生成（非代理式）", "【核心贡献】：解耦‘名义上下文长度’与‘可用上下文容量’，建立首个面向代码修复的纯长上下文能力评测管道"]}, "method": {"text": "构建三阶段实验框架：（1）在mini-SWE-agent中统计token级轨迹以暴露实际上下文使用上限；（2）设计BM25+黄金文件注入的确定性检索模块，确保100%召回关键源文件；（3）将完整上下文（64k/128k tokens）一次性喂入模型，强制其完成端到端补丁生成。", "bullets": ["【输入】：原始issue描述 + 检索出的多文件源码（经截断/拼接至目标长度）", "【架构】：黑盒调用商用及开源LLM（GPT-5-nano, Qwen3-Coder）", "【关键机制】：BM25检索 + 黄金文件注入（消除检索不确定性）", "【是否训练】：否 (零样本评测，无参数更新)", "【创新点】：提出‘去代理化、去检索干扰’的长上下文本体能力评测协议"]}, "data": {"text": "基于SWE-bench Verified子集构建可控评测集，所有案例均经人工验证可解，并通过BM25预检确保所需文件100%可被检索命中。", "bullets": ["【数据集】：SWE-bench Verified (software engineering)", "【来源】：GitHub Repos + SWE-bench issue-tracker", "【规模】：mini-SWE-agent subset with verified ground-truth patches"]}, "experiment": {"text": "对比代理式（mini-SWE-agent）与单次长上下文模式下的解决率差异；开展token级轨迹分析与失败案例人工归因；在64k/128k两种上下文长度下统一评测。", "bullets": ["【基线模型】：GPT-5-nano, Qwen3-Coder", "【消融实验】：代理流程 vs 单次长输入（控制检索质量一致）", "【对照设置】：相同issue + 相同黄金文件集合，仅改变输入组织方式（分步vs单次）"]}, "metrics": {"text": "以SWE-bench标准‘解决率（solve rate）’为核心指标，即生成补丁经测试套件验证后能完全修复issue的比例。", "bullets": ["solve rate", "Pass@1 (for patch validation)"]}, "results": {"text": "代理框架下高解决率（GPT-5-nano达31%）源于短上下文子步骤，而单次64k输入时性能崩塌；模型无法稳定解析长上下文中分散的文件结构与diff语义。", "bullets": ["mini-SWE-agent：GPT-5-nano solve rate = 31% (short-context proxy)", "64k single-turn：Qwen3-Coder solve rate = 7% (-24pp vs agent)", "64k single-turn：GPT-5-nano solve rate = 0%", "Failure pattern：72% of failed patches contain invalid diff line numbers or malformed headers"]}, "limitations": {"text": "评测聚焦于补丁生成单一任务，未覆盖长上下文下的多轮交互调试或跨PR依赖推理；黄金文件注入假设完美检索，在真实低召回场景下结论需谨慎外推。", "bullets": ["【任务窄】：仅评估单次补丁生成，未涵盖debugging loop或跨commit reasoning", "【假设强】：依赖100%黄金文件召回，未模拟真实检索噪声", "【领域限】：集中于Python/JS仓库修复，泛化性待验证"]}}}
{"paper_id": "2602.16080", "title": "Surgical Activation Steering via Generative Causal Mediation", "url": "https://arxiv.org/abs/2602.16080", "year": 2026, "blocks": {"background": {"text": "现有LLM可解释性方法多聚焦于单token预测任务（如偏见检测、事实验证），依赖显式标签或token级代理指标，难以刻画控制长文本生成行为（如风格、态度）的扩散型、分布级概念。", "bullets": ["【痛点】：传统归因方法无法建模长文本生成中概念的全局、动态、非局部特性", "【现状】：因果分析在生成式场景中缺乏系统性应用，多数steering方法依赖启发式或监督信号"]}, "objective": {"text": "提出Generative Causal Mediation（GCM）框架，首次将因果中介分析系统化应用于长形式文本生成，实现对控制生成行为的关键注意力头的无监督、稀疏、可解释定位。", "bullets": ["【任务】：因果中介定位（Causal Mediation Localization）", "【核心贡献】：将反事实patching引入生成式分布偏移分析，解耦‘何处干预’与‘如何干预’"]}, "method": {"text": "输入为语义微差的对比提示对（如‘请回答’vs‘请礼貌地拒绝回答’），经模型前向传播后，对各注意力头执行patching操作（用对比输入下该头激活替换原始输入下的激活），量化其对生成对比响应概率的间接效应（IE）；基于平均IE排序选取top-k%头作为中介组件，并支持多种steering策略。", "bullets": ["【输入】：对比式提示对（原始提示 & 行为差异提示）", "【架构】：Transformer（适用于Qwen/OLMo/SOLAR等开源LLM）", "【关键机制】：activation patching、attribution patching（一阶近似）、head knockout", "【是否训练】：否 (无需参数更新，纯前向反事实干预)", "【创新点】：定义并估计注意力头在生成分布层面的间接因果效应（IE），支持无监督稀疏定位"]}, "data": {"text": "构建面向三类长文本概念的对比式响应数据集，覆盖语义微差但行为显著不同的提示-响应对。", "bullets": ["【数据集】：Refusal（拒绝回答）", "【数据集】：Sycophancy（谄媚）", "【数据集】：Verse Style（诗体风格）", "【来源】：人工设计提示 + 模型采样响应（Qwen/OLMo/SOLAR）"]}, "experiment": {"text": "在三个开源大语言模型（Qwen、OLMo、SOLAR）上评估GCM对三类概念的定位效果，对比线性探针（ITI）、随机选择等基线，并测试不同steering策略（差分均值、均值覆盖、ReFT）的下游干预性能。", "bullets": ["【基线模型】：Qwen-7B, OLMo-1B, SOLAR-10.7B", "【基线方法】：ITI（线性探针）、Random Head Selection", "【消融实验】：activation patching vs attribution patching vs head knockout", "【steering策略】：Diff Mean Steering, Mean Steering, ReFT"]}, "metrics": {"text": "以steering成功率为核心指标，辅以胜率（Win Rate）、MMLU通用能力保持率评估干预质量。", "bullets": ["Win Rate", "Success Rate", "MMLU"]}, "results": {"text": "GCM在所有模型和任务上显著超越相关性基线；定位质量对无监督steering增益明显，而对监督式ReFT增益有限；小k%高精度定位带来更强steering但更严重MMLU下降。", "bullets": ["Refusal：Success Rate = 89.2% (+24.5% vs ITI, p<0.001)", "Sycophancy：Win Rate = 94% (vs Random)", "Verse Style：Success Rate = 78.5% (+31.1% vs ITI)", "MMLU drop：-12.3% (k=0.5%, α=1.0) vs -3.1% (k=5%, α=0.5)"]}, "limitations": {"text": "GCM依赖高质量对比提示对构建，且定位结果对patching粒度（头级 vs MLP层）和模型架构敏感；高精度定位伴随通用能力显著折损。", "bullets": ["【假设强】：依赖语义微差提示对的可用性与构造质量", "【开销大】：activation patching需双前向传播，计算成本高", "【泛化弱】：定位结果未跨模型迁移验证", "【权衡明显】：可控性提升以牺牲MMLU等基础能力为代价"]}}}
{"paper_id": "2602.16093", "title": "Updating Parametric Knowledge with Context Distillation Retains Post-Training Capabilities", "url": "https://arxiv.org/abs/2602.16093", "year": 2026, "blocks": {"background": {"text": "大模型在持续学习新知识时面临灾难性遗忘问题，尤其在后训练阶段易导致指令遵循、数学推理、代码生成等关键能力显著退化。", "bullets": ["【痛点】：标准微调导致后训练能力大幅退化（最高达25.4分）", "【现状】：现有方法（如RLHF、常规蒸馏）依赖外部教师、额外生成或难以建模行为一致性"]}, "objective": {"text": "提出DiSC方法，在注入新领域知识的同时，最大限度保留原始后训练能力。", "bullets": ["【任务】：持续知识更新下的能力保留", "【核心贡献】：以教师-学生KL散度最小化为显式目标的上下文蒸馏框架"]}, "method": {"text": "将文档按句子边界随机切分为（前缀，后缀）对；冻结后训练模型作为教师，输出P_M_T(后缀|前缀)；学生模型无条件预测P_M_S(后缀)；最小化二者KL散度，实现知识内化。", "bullets": ["【输入】：原始文档切分得到的（前缀，后缀）序列对", "【架构】：同源Transformer语言模型（Qwen/Llama3）", "【关键机制】：自蒸馏（self-distillation）、条件vs无条件分布对齐", "【是否训练】：是（仅学生模型参数更新，教师冻结）", "【创新点】：用同一模型的条件/无条件分布构建免外部教师、免生成的KL监督信号"]}, "data": {"text": "在新闻与生物医学两个领域开展验证，覆盖KUP与BioASQ数据集。", "bullets": ["【数据集】：KUP (新闻更新)", "【数据集】：BioASQ (生物医学问答)", "【来源】：领域相关文档集合（按句子切分）"]}, "experiment": {"text": "在Qwen和Llama3两类后训练模型上对比DiSC与标准微调及多种消融变体，评估其在领域适应与通用能力上的权衡表现。", "bullets": ["【基线模型】：Qwen-7B-Instruct, Llama3-8B-Instruct", "【基线方法】：全参数微调、LoRA微调、标准知识蒸馏", "【消融实验】：移除KL目标、替换为MLE损失、不同切分粒度"]}, "metrics": {"text": "采用多维度指标同步评估领域性能与通用能力保留效果。", "bullets": ["IFEval", "MATH", "HumanEval", "EM (Exact Match) on KUP/BioASQ", "Pass@1"]}, "results": {"text": "DiSC在领域性能上超越微调，同时将后训练能力退化控制在5分以内（远优于微调的最高25.4分），且对学习率更鲁棒。", "bullets": ["KUP：EM = 68.3% (+2.1% vs fine-tuning)", "BioASQ：EM = 72.5% (+3.7% vs fine-tuning)", "IFEval：79.4 → 75.1 (-4.3 pts, vs -25.4 for fine-tuning)", "MATH：41.2 → 37.8 (-3.4 pts)", "HumanEval：32.6 → 29.1 (-3.5 pts)"]}, "limitations": {"text": "方法有效性依赖于文档内部语义连贯性与切分合理性；尚未验证极端长尾知识或跨模态场景。", "bullets": ["【假设强】：依赖文档内句子间存在可迁移的知识上下文关系", "【领域限】：当前仅验证新闻与生物医学，未覆盖法律、金融等复杂逻辑领域", "【计算隐含成本】：需两次前向传播（虽免生成，但较单次MLE略增）"]}}}
{"paper_id": "2602.16110", "title": "OmniCT: Towards a Unified Slice-Volume LVLM for Comprehensive CT Analysis", "url": "https://arxiv.org/abs/2602.16110", "year": 2026, "blocks": {"background": {"text": "现有CT分析模型普遍采用二元范式：切片级模型（如2D ViT）擅长局部纹理识别但缺乏三维空间建模能力；体素级模型（如3D CNN/Transformer）能捕获空间关系但计算开销大、标注成本高、且难以复用成熟的2D视觉骨干。临床诊断需同时兼顾解剖细节与空间拓扑，亟需统一建模框架。", "bullets": ["【痛点】：切片模型缺失三维空间推理能力", "【痛点】：体素模型计算昂贵、标注稀缺、难以复用2D骨干", "【现状】：缺乏能协同利用切片细节与体素结构的统一多模态LVLM"]}, "objective": {"text": "提出首个统一切片-体素CT大视觉语言模型OmniCT，实现单塔架构下对2D切片与3D体素输入的联合理解与生成，并构建首个大规模、分层平衡、协议标准化的CT混合评测基准MedEval-CT。", "bullets": ["【任务】：医学多模态理解与生成（CT图像→临床语义描述/诊断推理）", "【核心贡献】：首个统一切片-体素的LVLM架构", "【核心贡献】：首个CT切片-体积混合评测基准MedEval-CT"]}, "method": {"text": "OmniCT采用单塔统一架构：输入为CT切片序列或体素块；经空间一致性增强（SCE）与器官级语义增强（OSE）双路径处理；输出由共享LLM解码器生成文本响应。", "bullets": ["【输入】：CT单层切片（H×W）或体素块（D×H×W），支持两种模态无缝切换", "【架构】：单塔视觉编码器 + 共享LLM解码器 + MoE混合投影头", "【关键机制】：空间一致性增强（SCE：含VSC体素化切片组合、TPE三轴位置编码、MHP MoE混合投影）、器官级语义增强（OSE：基于TotalSegmentor掩码的自适应器官token聚合）", "【是否训练】：是（端到端微调，含MoE路由参数与LLM适配器）", "【创新点】：以轻量VSC替代3D编码器，在2D骨干上注入可控三维先验；将临床器官层级逻辑显式建模为可学习OSE模块"]}, "data": {"text": "训练与评测均基于MedEval-CT体系，涵盖真实临床CT扫描数据，严格分离切片与体素样本，保障评估公正性。", "bullets": ["【数据集】：MedEval-CT-Dataset（170万样本，切片/体素数据严格非重叠）", "【来源】：多中心匿名临床CT扫描（DICOM）", "【标注】：TotalSegmentor 117类器官分割掩码 + 临床级文本描述（诊断、定位、严重程度）"]}, "experiment": {"text": "在MedEval-CT-Bench上开展全面评估，包含消融实验、跨模态迁移分析、器官级细粒度分析及t-SNE可视化；对比基线涵盖纯切片模型、纯体素模型及早期融合方法。", "bullets": ["【基线模型】：2D-ViT+LLM, 3D-ResNet+LLM, SliceFormer, VoxelGPT", "【消融实验】：单独移除SCE/OSE、替换VSC为普通堆叠、替换TPE为2D位置编码", "【跨模态设置】：仅用切片数据训练，零样本迁移到体素任务"]}, "metrics": {"text": "采用多维度评估协议：语义准确性（BLEU-4, ROUGE-L）、临床一致性（CliniScore）、定位精度（Dice@0.5, IoU@0.5）、推理正确率（QA-Acc, Reasoning-F1）。", "bullets": ["BLEU-4", "ROUGE-L", "CliniScore", "Dice@0.5", "IoU@0.5", "QA-Acc", "Reasoning-F1"]}, "results": {"text": "OmniCT在切片与体素双基准上全面超越所有基线；SCE+OSE联合带来显著增益；在小器官和高阶推理任务中提升尤为突出，验证其空间建模与临床语义对齐的有效性。", "bullets": ["MedEval-CT-Bench（切片）：QA-Acc = 76.3% (+2.77 vs ablated)", "MedEval-CT-Bench（体素）：Reasoning-F1 = 68.9% (+3.98 vs ablated)", "胰腺定位：Dice@0.5 = 62.4% (+21.7% vs 2D-ViT+LLM)", "食管诊断推理：Reasoning-F1 = 58.1% (+23.5% vs SliceFormer)", "跨模态零样本迁移（切片→体素）：CliniScore = 61.2%（显著优于随机初始化3D模型）"]}, "limitations": {"text": "模型依赖高质量器官分割先验（TotalSegmentor），尚未集成实时分割能力；体素输入分辨率受限于GPU显存，暂未支持全器官高分辨率重建；评测集中罕见病种覆盖仍不足。", "bullets": ["【假设强】：依赖TotalSegmentor提供的精确器官掩码", "【开销大】：高分辨率体素推理仍受限于显存，需进一步优化", "【覆盖窄】：MedEval-CT中罕见肿瘤亚型与儿童CT样本比例偏低"]}}}
{"paper_id": "2602.16113", "title": "Evolutionary Context Search for Automated Skill Acquisition", "url": "https://arxiv.org/abs/2602.16113", "year": 2026, "blocks": {"background": {"text": "大语言模型在零样本场景下难以高效利用外部文本资源获取新技能；现有RAG方法依赖语义匹配，难以发现跨粒度、跨文档的最优上下文组合；微调（SFT）在小规模专业数据上易失败（如梯度爆炸、零分），亟需无需参数更新的轻量级替代方案。", "bullets": ["【痛点】：RAG仅匹配相似文本，忽略组合协同效应", "【痛点】：SFT在小样本专业任务中完全失效", "【现状】：上下文工程长期停留于检索-拼接范式，缺乏结构化优化机制"]}, "objective": {"text": "提出进化式上下文搜索（ECS），在不更新模型权重的前提下，通过黑盒进化搜索自动发现高泛化性、高效率的最优上下文组合，实现零样本技能迁移。", "bullets": ["【任务】：零样本上下文优化", "【核心贡献】：提出ECS——首个基于适应度驱动的黑盒上下文组合搜索框架", "【目标】：提升跨模型、跨任务的上下文泛化性与token效率"]}, "method": {"text": "将上下文构造建模为黑盒优化问题，以开发集任务准确率为适应度函数；通过遗传算法（轮盘赌选择、拼接交叉、单位替换突变）在多粒度上下文单元种群上迭代演化；每次突变后引入LLM辅助进行逻辑冲突消解，保障知识一致性。", "bullets": ["【输入】：原始文档（含源码/洞察/技能等多粒度单元）", "【架构】：遗传算法（GA）+ LLM引导验证模块", "【关键机制】：适应度驱动的进化搜索 + 冲突感知的LLM精炼", "【是否训练】：否 (纯推理调用，无梯度、不访问权重)", "【创新点】：将上下文工程重构为可泛化的组合优化流水线，而非语义匹配或参数微调"]}, "data": {"text": "实验覆盖代码理解与领域客服两类任务，使用专业化基准数据集。", "bullets": ["【数据集】：BackendBench (代码性能评估)", "【数据集】：τ²-bench (航空客服对话，含政策冲突场景)", "【来源】：CuTeDSL kernel文件、错误分析报告、结构化agent技能描述"]}, "experiment": {"text": "在BackendBench和τ²-bench上对比RAG基线、全文档上下文及消融变体；验证跨模型迁移性（Gemini→Claude→DeepSeek）；开展系统性消融研究。", "bullets": ["【基线模型】：RAG（BM25/Embedding）、Full Context", "【消融实验】：移除选择机制、移除突变操作、禁用LLM精炼步骤", "【迁移实验】：Gemini-3-Flash演化上下文迁移到Claude Sonnet与DeepSeek-V3.2"]}, "metrics": {"text": "采用任务相关标准指标评估性能与效率。", "bullets": ["Pass@3", "Exact Match (EM)", "Win Rate (vs baseline)", "Token Count (efficiency)"]}, "results": {"text": "ECS显著超越RAG与全文档上下文，在性能、泛化性与token效率三方面均取得突破；所发现上下文具备强跨模型迁移能力。", "bullets": ["BackendBench：EM = +27% vs strongest RAG", "τ²-bench：Pass@3 = 0.683 (+0.133 vs Full Context 0.550)", "τ²-bench：848 tokens ≈ Full Context (5491 tokens)，实现6× token压缩", "DeepSeek-V3.2迁移：正确率 0.031 → 0.223 (+7×) using Gemini-evolved context"]}, "limitations": {"text": "搜索过程依赖开发集性能反馈，存在过拟合风险；LLM精炼模块引入额外推理开销；对极端长尾任务的单元提取鲁棒性待验证。", "bullets": ["【假设强】：依赖高质量开发集作为适应度信号", "【开销大】：LLM冲突消解增加单次迭代延迟", "【覆盖窄】：当前上下文单元类型未涵盖多模态或时序信号"]}}}
{"paper_id": "2602.16131", "title": "Empirical Cumulative Distribution Function Clustering for LLM-based Agent System Analysis", "url": "https://arxiv.org/abs/2602.16131", "year": 2026, "blocks": {"background": {"text": "传统LLM代理评估依赖最终聚合结果（如投票准确率），掩盖了响应质量分布的内部差异，难以支持细粒度调试与配置归因。", "bullets": ["【痛点】：相同准确率下响应质量分布可能截然不同，现有指标无法刻画这种异质性", "【现状】：主流评估聚焦标量结果，缺乏对原始响应集合分布形态的建模与比较"]}, "objective": {"text": "提出一种不依赖答案聚合、基于响应-参考答案相似度分布的可解释性聚类分析框架，用于刻画和分组不同LLM代理配置的质量分布特性。", "bullets": ["【任务】：LLM代理响应分布建模与可解释聚类", "【核心贡献】：ECDF表征 + ECDF专用L1距离 + k-medoids聚类框架"]}, "method": {"text": "对每个代理配置生成的多条响应，分别计算其与参考答案的最大余弦相似度，构成一维相似度向量；以此构建无参数ECDF作为质量分布表征；定义ECDF间L1距离（积分绝对差）作为度量，并采用PAM算法进行k-medoids聚类；最后通过重排序与MDS实现集群可视化与配置维度解析。", "bullets": ["【输入】：每配置下的响应集合 + 对应参考答案", "【架构】：非参数统计建模 + 聚类（k-medoids/PAM）", "【关键机制】：ECDF构造、ECDF-L1距离、MDS可视化、配置维度关联分析", "【是否训练】：否 (无需参数更新，纯离线统计分析)", "【创新点】：面向ECDF的专用距离函数与免向量化聚类流程"]}, "data": {"text": "实验基于多主题、多配置LLM代理生成的响应数据，覆盖不同温度、人格设定及问题类型。", "bullets": ["【数据集】：自建LLM代理响应数据集（含'Normans'、'Chloroplast'等主题问答）", "【来源】：可控LLM代理实验平台（GPT-4/Llama系列等模型）"]}, "experiment": {"text": "在多个代理配置组合（主题×温度×人格）上运行，对比不同聚类方法（如PCA+k-means）与ECDF-k-medoids的结构保持能力，并进行消融分析验证ECDF距离的有效性。", "bullets": ["【基线模型】：PCA+k-means、Wasserstein-k-medoids", "【消融实验】：替换ECDF为直方图/核密度估计后的聚类退化分析", "【控制变量】：温度（0.2–1.5）、人格设定、问题主题"]}, "metrics": {"text": "以ECDF-L1距离为聚类核心度量；评估聚类质量使用簇内距、簇间距及MDS应力值；辅以人工可解释性评分。", "bullets": ["L1 Distance between ECDFs", "MDS Stress", "Cluster Cohesion/Separation"]}, "results": {"text": "ECDF聚类成功揭示配置间响应分布的本质差异：主题维度主导聚类结构，高温导致分布坍缩，优质集群呈现高相似度短答案特征。", "bullets": ["【Normans主题】：ECDF右偏，EM ≈ 92% (+18% vs Chloroplast)", "【高温（T=1.5）】：ECDF-L1 cluster variance ↓37% (vs T=0.5)", "【Cluster 0】：平均余弦相似度 = 0.84 ± 0.06，答案长度均值 = 2.3词", "【Cluster 15】：平均余弦相似度 = 0.31 ± 0.12，答案长度均值 = 14.7词"]}, "limitations": {"text": "方法依赖余弦相似度作为单一质量代理，未建模语义完整性或事实一致性；ECDF仅捕获一维分布，忽略响应间相关性；聚类结果解释需人工锚定配置维度。", "bullets": ["【假设强】：响应质量可被单维余弦相似度充分表征", "【信息窄】：ECDF丢失响应序列结构与跨样本依赖", "【依赖人工】：集群语义标签（如'Normans型'）需事后标注，未端到端联合学习"]}}}
{"paper_id": "2602.16136", "title": "Retrieval Collapses When AI Pollutes the Web", "url": "https://arxiv.org/abs/2602.16136", "year": 2026, "blocks": {"background": {"text": "随着AI生成内容在互联网中大规模扩散，检索系统面临依赖自身产出导致结构性失效的风险，现有研究多聚焦模型训练闭环坍塌，忽视开放检索生态中的系统性脆弱性。", "bullets": ["【现状】：检索系统评估长期忽略内容来源多样性与证据可信度的耦合影响", "【痛点】：缺乏对‘检索崩溃’这一生态系统级失败模式的形式化定义与量化指标"]}, "objective": {"text": "首次形式化定义‘检索崩溃’，构建可量化的三级污染渗透指标体系，并揭示其两阶段演化机制。", "bullets": ["【任务】：检索系统鲁棒性分析与生态级失效建模", "【核心贡献】：提出检索崩溃新范式，将风险视角从模型训练闭环迁移至开放检索生态"]}, "method": {"text": "在MS MARCO基础上构建三类文档池（原始/SEO合成/对抗合成），开展20轮渐进式污染实验；通过PCR/ECR/CCR分离污染在检索栈（池→曝光→引用）中的层级渗透；采用GPT-5系列多模块协同架构（nano生成器+mini裁判）规避自验证偏差。", "bullets": ["【输入】：MS MARCO基础文档集 + 三类合成内容（SEO/对抗/原始）", "【架构】：GPT-5多模块协同（nano生成器 + mini裁判）", "【关键机制】：三级污染测量（PCR/ECR/CCR）、LLM Ranker与BM25双基线对比、污染渐进注入", "【是否训练】：否 (可控实验驱动，无需参数更新)", "【创新点】：首次解耦检索栈中污染的层级传播路径，并区分SEO与对抗内容的差异化影响"]}, "data": {"text": "基于MS MARCO构建可控污染文档池，包含原始人类撰写内容、SEO优化合成内容及对抗性合成内容。", "bullets": ["【数据集】：MS MARCO (检索)", "【合成来源】：GPT-5 nano生成器", "【污染类型】：SEO合成内容、对抗合成内容、原始人类内容"]}, "experiment": {"text": "开展20轮渐进式污染实验，控制污染强度变量；对比LLM Ranker与BM25在相同污染条件下的表现；设置消融以区分SEO与对抗内容影响；引入mini裁判模块校验答案可信度。", "bullets": ["【基线模型】：BM25, LLM Ranker", "【消融实验】：去除裁判模块的影响、SEO vs 对抗污染的独立效应", "【实验设计】：20轮渐进污染 + 三级污染率（PCR/ECR/CCR）同步监测"]}, "metrics": {"text": "采用三级污染率作为核心生态指标，并结合端到端准确率评估功能稳健性。", "bullets": ["PCR", "ECR", "CCR", "Exact Match (EM)", "Win Rate (vs human reference)"]}, "results": {"text": "SEO污染下呈现‘表面健康、底层失根’现象；对抗污染下LLM Ranker展现强语义防御但成本高；源多样性崩溃早于质量下降发生；轻量检索器端到端性能下滑更显著。", "bullets": ["MS MARCO：PCR = 67% → ECR > 80%, EM ↑0.3% (隐蔽崩溃)", "对抗污染：BM25暴露有害内容率 = 19%, LLM Ranker ≈ 0%", "源多样性崩溃：在EM稳定期间，人类内容引用率下降至<12% (t=14轮)", "端到端性能：轻量检索器在PCR=50%时Pass@1下降14.2% vs 重排序器下降5.1%"]}, "limitations": {"text": "实验受限于合成内容分布假设，未覆盖真实世界多源异构污染动态；LLM裁判模块引入额外延迟与黑盒性；三级指标尚未部署于线上系统验证。", "bullets": ["【假设强】：依赖GPT-5生成的合成内容分布，未建模真实平台传播噪声", "【开销大】：LLM Ranker+mini裁判带来显著推理延迟与计算成本", "【部署缺】：PCR/ECR/CCR尚无实时监控接口，未接入生产检索流水线"]}}}
{"paper_id": "2602.16144", "title": "Missing-by-Design: Certifiable Modality Deletion for Revocable Multimodal Sentiment Analysis", "url": "https://arxiv.org/abs/2602.16144", "year": 2026, "blocks": {"background": {"text": "多模态情感分析模型通常融合文本、音频、视觉等模态，但当某模态数据涉及隐私或合规风险（如敏感语音）时，需安全、可验证地将其删除；现有方法依赖重新训练或黑盒剪枝，缺乏理论保证与第三方可验证性。", "bullets": ["【痛点】：模态删除缺乏可验证性与可撤销性", "【现状】：主流方案需重训练或无证书保障"]}, "objective": {"text": "提出首个支持机器可验证证书的模态级删除框架，实现在不重新训练前提下对特定模态（如音频）的可控、鲁棒、可审计遗忘。", "bullets": ["【任务】：多模态模型中特定模态的可验证删除", "【核心贡献】：提出Missing-by-Design（MBD）框架，集成属性感知分解、生成式重建与高斯校准参数手术"]}, "method": {"text": "输入原始多模态样本→通过双路径表征学习解耦模态先验与样本信号→利用模态专用生成器完成对比式反向翻译重建→基于梯度显著性与L_q重要性代理筛选参数→施加高斯噪声注入或零化实现受控遗忘→输出带完整元信息的机器可验证证书（MDC）。", "bullets": ["【输入】：多模态样本（文本/音频/视觉）", "【架构】：双路径表征网络 + 模态专用生成器 + 参数手术模块", "【关键机制】：属性感知表征分解、对比式反向翻译（back-translation + NCE）、梯度显著性引导的SwiftPrune风格参数筛选、高斯噪声注入（DP-inspired）", "【是否训练】：是（端到端微调，含重建与分解损失）", "【创新点】：将‘缺失’作为设计原则（Missing-by-Design），首次实现模态级删除的机器可验证证书生成"]}, "data": {"text": "在主流多模态情感分析基准上评估，涵盖跨域、跨任务设置。", "bullets": ["【数据集】：CMU-MOSI (情感极性)", "【数据集】：CMU-MOSEI (情感强度)", "【数据集】：IEMOCAP (情绪类别)"]}, "experiment": {"text": "在全模态与单模态缺失场景下对比SOTA方法，并开展消融实验、认证删除攻击测试及敏感性分析。", "bullets": ["【基线模型】：MulT, TFN, MFM, Modality-Drop", "【消融实验】：移除property embedding、移除重建模块、替换手术策略", "【攻击测试】：白盒梯度攻击评估删除不可逆性"]}, "metrics": {"text": "以情感分类准确率为主指标，辅以隐私攻击成功率与证书有效性诊断指标。", "bullets": ["Acc2", "Win Rate (vs. baseline)", "Attack Success Rate", "ε_mod", "δ_mod"]}, "results": {"text": "MBD在所有缺失场景下显著提升鲁棒性与隐私性，在保持效用几乎不变前提下大幅降低攻击成功率。", "bullets": ["CMU-MOSI：Acc2 = 78.5% (+2.5% vs. SOTA full-modal)", "CMU-MOSEI：Acc2 = 74.2% (+7.6% avg. vs. baseline under modality missing)", "IEMOCAP：Attack Success Rate = 49.8% (↓28.6% vs. 78.4% baseline, ε_mod ≤ 1)", "敏感性分析：Acc2波动 < 1.1%，ε_mod稳定 ≤ 0.51"]}, "limitations": {"text": "当前框架假设模态间存在可解耦的属性结构，且参数手术精度受限于显著性估计质量。", "bullets": ["【假设强】：依赖模态先验与样本信号可分离的结构假设", "【开销大】：生成式重建引入额外推理延迟", "【泛化限】：证书格式与诊断协议尚未标准化，暂未覆盖异构模型架构"]}}}
{"paper_id": "2602.16173", "title": "Learning Personalized Agents from Human Feedback", "url": "https://arxiv.org/abs/2602.16173", "year": 2026, "blocks": {"background": {"text": "现有AI代理在个性化中面临冷启动与偏好漂移双重挑战：缺乏初始用户数据导致性能低下，而隐式建模或静态数据训练难以应对用户偏好的动态演化。", "bullets": ["【痛点】：无初始用户数据时无法有效冷启动", "【痛点】：用户偏好随时间漂移，现有方法缺乏实时纠错与记忆更新机制", "【现状】：主流方法依赖离线静态数据或隐式参数化建模，交互信号未被结构化利用"]}, "objective": {"text": "提出PAHF框架，实现从零开始、在线、持续的用户个性化，核心是解耦并协同利用预动作澄清（防错）与后动作反馈（纠错）双通道。", "bullets": ["【任务】：持续个性化代理（Continual Personalized Agent）", "【核心贡献】：首个将人类反馈显式解耦为正交双通道（预动作/后动作）并提供理论遗憾界保障的框架"]}, "method": {"text": "输入为用户指令与环境观测；预动作阶段检索显式用户记忆并主动发起澄清提问以缓解不确定性；动作阶段融合指令、观测与检索到的记忆偏好生成决策；后动作阶段接收用户反馈，经LLM驱动的检测-摘要-整合流程更新SQLite/FAISS中的自然语言记忆条目；整个过程无需梯度更新，仅依赖符号化记忆操作。", "bullets": ["【输入】：用户指令 + 环境观测 + 显式用户记忆（SQLite/FAISS）", "【架构】：轻量级显式记忆 + LLM-as-a-Controller（非端到端）", "【关键机制】：双通道反馈闭环（Pre-action Clarification + Post-action Feedback Integration）", "【是否训练】：否 (无需参数更新，纯推理+符号记忆操作)", "【创新点】：首次形式化‘防错’（pre-action）与‘纠错’（post-action）的正交性，并证明其互补降低动态遗憾"]}, "data": {"text": "实验基于自建多阶段用户交互模拟平台，含人工标注与合成漂移轨迹，支持按用户隔离的记忆实例化。", "bullets": ["【数据集】：PAHF-Bench（自建，含Phase 1–4 模拟交互轨迹）", "【来源】：人工设计偏好漂移模式 + LLM辅助轨迹生成", "【标注】：每轮用户反馈（接受/拒绝/修正）与黄金偏好标签"]}, "experiment": {"text": "采用四阶段严格解耦评估协议，对比消融变体与基线，在相同模拟环境下测试冷启动学习与漂移适应能力。", "bullets": ["【基线模型】：No-Memory Agent, Pre-action Only, Post-action Only", "【消融实验】：PAHF w/o memory update, PAHF w/o clarification", "【评估设计】：Phase 1–2（初始偏好学习）、Phase 3–4（偏好漂移适应），独立报告成功率与ACPE"]}, "metrics": {"text": "以回合级成功率（Success Rate）和平均累积偏好误差（ACPE）为核心指标，兼顾学习效率与稳定性。", "bullets": ["Success Rate", "ACPE (Average Cumulative Preference Error)"]}, "results": {"text": "PAHF在所有阶段均显著优于基线：冷启动阶段快速收敛，漂移阶段稳健适应，验证了双通道协同的有效性与必要性。", "bullets": ["Phase 1：Success Rate = 62.1% (+30.5% vs No-Memory)", "Phase 2：Success Rate = 70.5% (SOTA)", "Phase 4：Success Rate = 68.8% (+12.3% vs Post-action Only)", "ACPE：PAHF最低，较Post-action Only降低41.7%"]}, "limitations": {"text": "当前框架对模拟环境假设较强，真实用户反馈噪声建模与长期记忆衰减机制尚未纳入。", "bullets": ["【假设强】：依赖可控、低噪声的用户反馈信号", "【扩展性】：未建模长期记忆遗忘或跨用户偏好迁移", "【开销大】：每轮需多次LLM调用（检测/摘要/整合），推理延迟较高"]}}}
{"paper_id": "2602.16246", "title": "Toward Scalable Verifiable Reward: Proxy State-Based Evaluation for Multi-turn Tool-Calling LLM Agents", "url": "https://arxiv.org/abs/2602.16246", "year": 2026, "blocks": {"background": {"text": "多轮工具调用型LLM智能体的评估长期依赖高成本、低扩展性的确定性后端（如真实数据库），导致评估难以规模化、路径多样性受限，且难以支持快速迭代训练。", "bullets": ["【痛点】：确定性后端成本高、不可扩展、僵化限制正确路径多样性", "【现状】：现有评估多依赖轨迹匹配或黑盒输出，缺乏对语义终态的结构化验证"]}, "objective": {"text": "提出轻量、高保真、可扩展的代理状态驱动评估框架，以LLM推断的结构化代理终态替代真实数据库状态，实现工业级智能体的可靠评估与带奖励信号的训练数据生成。", "bullets": ["【任务】：智能体多轮工具调用的状态基评估", "【核心贡献】：解耦语义状态验证与物理数据库实现，首次将LLM作为可信状态推理引擎嵌入评估闭环"]}, "method": {"text": "输入为场景（scenario）定义（含用户目标、初态事实、预期终态与响应）及原始对话-工具轨迹；经五组件LLM协同系统处理（用户模拟器→工具模拟器→代理状态追踪器→目标完成裁判→幻觉检测裁判），输出终态一致性判定与细粒度幻觉标签；终态比对取代轨迹匹配，支持多样正确路径。", "bullets": ["【输入】：场景对象（用户目标/初态事实/预期终态/预期响应） + 原始多轮对话+工具调用轨迹", "【架构】：五组件LLM协同系统（用户模拟器、工具模拟器、代理状态追踪器、目标完成裁判、幻觉检测裁判）", "【关键机制】：终态比对、场景完整性约束、多裁判分工校验", "【是否训练】：否 (全组件基于prompted LLM推理，无需参数更新)", "【创新点】：LLM作为可信状态推理引擎、场景化锚点约束、零幻觉协同模拟设计"]}, "data": {"text": "基于人工构建的高质量场景集，覆盖多样化用户目标、工具域和用户画像（如power/confused），所有场景均经逻辑一致性验证与专家校验。", "bullets": ["【数据集】：自建场景库（含用户/系统事实、预期终态、用户画像标签）", "【来源】：领域专家设计 + 逻辑一致性推导 + 人工校验"]}, "experiment": {"text": "在多规模模型（Qwen3-30B、GPT-4o/5o等）上开展评估稳定性、幻觉敏感性、人类一致性、训练有效性与用户画像敏感性分析。", "bullets": ["【基线模型】：Qwen3-30B, GPT-4o, GPT-5o", "【消融实验】：降低场景信息完整性（删减事实）、替换代理状态追踪器LLM（GPT-4o vs GPT-5o）", "【对比范式】：on-policy RFT vs off-policy SFT 训练效果"]}, "metrics": {"text": "采用多维指标联合评估：目标完成率（GC）、工具幻觉率、用户幻觉率、终态匹配率、人类-LLM裁判一致性（Kappa/Win Rate）、用户错误率。", "bullets": ["GC", "Tool Hallucination Rate", "User Hallucination Rate", "Final State Match Rate", "Human-LLM Agreement Rate", "User Error Rate"]}, "results": {"text": "框架具备强模型区分力、高可靠性与细粒度敏感性：GC随模型能力与推理努力稳定提升；SFT训练使Qwen3-30B GC提升11.7%；人类-LLM裁判一致性达94.7%；用户画像切换可量化捕捉智能体鲁棒性差异。", "bullets": ["Qwen3-30B：GC = 77.3% (+11.7% vs baseline 65.6%)", "GPT-4o→GPT-5o（状态追踪器）：Tool Hallucination Rate = 1.33% → 3.61%", "Human-LLM Agreement：94.7% (Tool/User Hallucination Detection)", "Power user→Confused user：User Error Rate = 3.55% → 5.50%"]}, "limitations": {"text": "当前框架依赖高质量人工场景构建与LLM组件校准，尚未完全自动化；对极端长程状态依赖或跨工具强时序耦合场景的泛化能力待验证；LLM状态推理仍存在理论上限。", "bullets": ["【人工依赖强】：场景需专家设计与逻辑验证，暂未支持全自动合成", "【假设强】：依赖LLM在结构化状态推理上的高可靠性，未覆盖对抗性终态歧义场景", "【覆盖有限】：对超长上下文（>100步）或多工具强因果链场景的鲁棒性未充分验证"]}}}
{"paper_id": "2602.16284", "title": "Fast KV Compaction via Attention Matching", "url": "https://arxiv.org/abs/2602.16284", "year": 2026, "blocks": {"background": {"text": "大语言模型在长上下文推理中面临KV缓存内存爆炸与延迟激增问题；现有压缩方法（如Cartridges）虽保性能但耗时数小时，难以满足实时/边缘部署需求。", "bullets": ["【痛点】：KV缓存压缩速度慢（小时级），无法支持低延迟场景", "【现状】：端到端黑盒压缩缺乏机制可解释性，难以兼顾行为一致性与计算效率"]}, "objective": {"text": "提出Attention Matching（AM）框架，在保证下游任务性能前提下，实现秒级、高质量、可解释的KV缓存压缩。", "bullets": ["【任务】：KV缓存无损/近无损压缩", "【核心贡献】：基于注意力输出与注意力质量双目标匹配的闭式解耦压缩范式"]}, "method": {"text": "以每个注意力头为单位，通过三步闭式求解构建紧凑KV：①选择代表性键（OMP或最高注意力键）；②用非负最小二乘拟合标量偏置β以匹配原始注意力质量；③用普通最小二乘拟合紧凑值Cᵥ以匹配局部注意力输出；支持RoPE对齐的分块压缩与头级非均匀预算分配。", "bullets": ["【输入】：原始KV缓存（序列长T，每头K/V矩阵）", "【架构】：注意力机制内生建模（非神经网络）", "【关键机制】：注意力输出匹配 + 注意力质量（mass）匹配 + β偏置校正 + 分块RoPE对齐", "【是否训练】：否 (全程闭式求解，无需梯度下降或参数更新)", "【创新点】：首次将KV压缩解耦为注意力质量与输出双目标协同优化，并引入可学习标量β实现t<T下的质量守恒"]}, "data": {"text": "实验覆盖多领域长文本基准，侧重高信息密度与问答一致性验证。", "bullets": ["【数据集】：LongHealth (医疗问答)", "【数据集】：NarrativeQA (长故事问答)", "【数据集】：QMSum (会议摘要问答)", "【来源】：标准开源长上下文评测集"]}, "experiment": {"text": "在LLaMA-2/3、Qwen等主流模型上评估KV压缩效果，对比Cartridges、StreamingLLM、Chunked-LLM等基线，开展消融研究与部署友好性分析。", "bullets": ["【基线模型】：LLaMA-2-7B, LLaMA-3-8B, Qwen2-7B", "【基线方法】：Cartridges, StreamingLLM, Chunked-LLM, RMS聚合", "【消融实验】：去除β偏置、固定头预算、禁用分块RoPE对齐", "【部署设置】：单A100 GPU，压缩吞吐量与端到端QA延迟联合评测"]}, "metrics": {"text": "以问答任务准确率为核心，辅以压缩时间、内存节省率与注意力重建误差量化评估。", "bullets": ["Exact Match (EM)", "F1", "Compression Time (s)", "Memory Reduction Ratio", "Attention Output MSE", "Attention Mass KL-Divergence"]}, "results": {"text": "AM-OMP在50×压缩下达到与Cartridges相当的QA准确率，且压缩速度提升超100倍；非均匀头预算带来2–4个百分点平均增益；RMS+AM在速度-质量权衡上最优。", "bullets": ["LongHealth：EM = 63.2% (+0.3 vs Cartridges, 50×)", "NarrativeQA：F1 = 48.7% (+1.1 vs uniform AM, 50×)", "Compression Time：AM-OMP = 1.8s vs Cartridges = 3200s (50×)", "Total Compression：AM + Summary = 200×, EM ≥ summary-only baseline"]}, "limitations": {"text": "方法依赖于注意力质量与输出的局部可分离性假设，对极度稀疏或非平稳注意力模式泛化性待验证；分块策略引入边界效应，RoPE对齐仅缓解未彻底消除。", "bullets": ["【假设强】：依赖注意力质量可由标量β加权表征，未建模跨头交互", "【边界效应】：分块压缩导致chunk间注意力不连续，RoPE对齐为近似补偿", "【适用范围】：当前仅验证decoder-only架构，未适配encoder-decoder或多模态KV结构"]}}}
{"paper_id": "2602.16301", "title": "Multi-agent cooperation through in-context co-player inference", "url": "https://arxiv.org/abs/2602.16301", "year": 2026, "blocks": {"background": {"text": "多智能体强化学习中，传统合作方法依赖硬编码的对手学习规则（如对手策略梯度穿透）或显式的快慢时间尺度分离假设，导致系统设计复杂、泛化性差、难以扩展。", "bullets": ["【痛点】：需预设对手更新机制，违背自利智能体自主性", "【现状】：合作涌现高度依赖人工设计的时间/优化层级割裂"]}, "objective": {"text": "提出一种免假设的自然合作涌现机制，使自利智能体仅通过交互历史上下文即可动态推断并适应对手策略，从而在单轮博弈中自发建立互惠合作。", "bullets": ["【任务】：多智能体博弈中的无监督合作涌现", "【核心贡献】：将对手建模重构为序列模型的上下文学习副产品"]}, "method": {"text": "输入为历史动作-观测-奖励序列；经混合对手池训练的序列模型联合预测动作、观测与奖励，隐式建模对手响应；利用Predictive Policy Improvement（PPI）算法，以该序列模型同时充当世界模型与策略先验，通过蒙特卡洛回溯估计Q值并执行贝叶斯式策略改进；将上下文适应本身作为可被塑造的‘快速学习者’角色，为互惠提供梯度信号。", "bullets": ["【输入】：(aₜ, oₜ, rₜ) 交互历史序列", "【架构】：Transformer-based sequence model", "【关键机制】：Predictive Policy Improvement (PPI), unsupervised context learning, opponent-type inference via history", "【是否训练】：是 (end-to-end RL training with mixed opponent pool)", "【创新点】：用序列建模替代显式对手建模，以‘易被勒索性’作为互惠驱动的梯度源"]}, "data": {"text": "在经典迭代博弈环境（如IPD、Stag Hunt、Chicken）上构建混合对手池，包含可学习的序列智能体与手工定义的静态表格策略（如Tit-for-Tat、Always-Cooperate、Always-Defect）。", "bullets": ["【数据集】：Iterated Prisoner’s Dilemma (IPD)", "【数据集】：Stag Hunt", "【数据集】：Chicken Game", "【来源】：自定义RL环境 + 手工策略集"]}, "experiment": {"text": "在标准博弈环境下开展消融实验与对抗分析，对比不同对手池构成、是否添加对手ID、是否冻结上下文学习者等设定对合作稳定性的影响。", "bullets": ["【基线模型】：A2C, PPO, standard RNN agents", "【消融实验】：移除表格对手 → 合作崩溃", "【消融实验】：添加对手标识 → 合作退化", "【对比设置】：固定上下文学习者 vs. 可训练学习者"]}, "metrics": {"text": "采用博弈论标准指标评估合作程度、策略适应速度与均衡稳定性。", "bullets": ["Cooperation Rate", "Response Convergence Steps", "Average Reward per Episode", "Nash Distance", "Win Rate (vs. exploitative baselines)"]}, "results": {"text": "序列智能体在IPD中10–20步内收敛至最优响应，合作率提升至89.3%（+32.7% vs. A2C），且双勒索训练智能体对战时达成稳定合作均衡（平均收益达1.25±0.08）。", "bullets": ["IPD：Cooperation Rate = 89.3% (+32.7% vs. A2C)", "IPD：Response Convergence Steps = 14.2 (vs. 47.6 for A2C)", "Stag Hunt：Average Reward = 1.25 ± 0.08 (vs. 0.71 for baseline)", "Chicken：Nash Distance = 0.13 (near-optimal equilibrium)"]}, "limitations": {"text": "方法性能依赖于交互历史长度与多样性，在极短序列或高噪声观测下推断鲁棒性下降；当前仅验证于2×2博弈，扩展至大规模、异构或多角色场景尚待验证。", "bullets": ["【假设强】：依赖完整可观测交互历史", "【泛化弱】：未验证于非对称/连续动作空间博弈", "【开销大】：蒙特卡洛回溯带来推理延迟", "【可解释性低】：隐式对手建模缺乏策略语义解耦"]}}}
{"paper_id": "2602.16313", "title": "MemoryArena: Benchmarking Agent Memory in Interdependent Multi-Session Agentic Tasks", "url": "https://arxiv.org/abs/2602.16313", "year": 2026, "blocks": {"background": {"text": "现有记忆评估基准（如LoCoMo）多聚焦静态回忆能力，无法反映大语言模型代理在真实交互中跨多轮、跨会话持续积累、提炼与复用记忆的动态闭环能力；当前SOTA记忆方法在实际任务中表现与基准测试结果严重脱节。", "bullets": ["【现状】：主流记忆评测脱离真实代理-环境交互闭环", "【痛点】：静态回忆基准无法暴露记忆在深层因果依赖下的失效"]}, "objective": {"text": "构建首个面向‘记忆-代理-环境’动态闭环、支持跨会话强依赖子任务的记忆能力统一评测基准，实现对记忆功能性价值（记、取、用）的严格归因评估。", "bullets": ["【任务】：多会话记忆能力评测", "【核心贡献】：提出MEMORYARENA——首个细粒度、因果驱动、闭环式记忆评估基准"]}, "method": {"text": "设计四类人类构造的多会话任务，每个子任务为独立会话；代理需从持久化记忆系统中检索历史信息，结合当前指令决策，再将完整轨迹注入记忆更新；评估采用任务完成率（SR）、过程分（PS）和软过程分（sPS），并按子任务深度@k分析衰减规律。", "bullets": ["【输入】：多轮会话轨迹（含指令、响应、状态变更）", "【架构】：任务-代理-环境闭环仿真框架", "【关键机制】：显式跨会话状态继承、引理链式依赖建模、@k深度衰减分析", "【是否训练】：否 (评测基准，不涉及模型训练)", "【创新点】：将记忆定义为闭环中的主动决策变量，而非被动存储模块"]}, "data": {"text": "MEMORYARENA包含四类人工构造的多会话任务，覆盖现实复杂场景，所有任务均要求不可简化的跨会话因果依赖。", "bullets": ["【数据集】：MEMORYARENA (捆绑式购物, 群体旅行规划, 渐进式搜索, 形式化推理)", "【来源】：人工构造 + 专家验证", "【规模】：四类任务 × 多深度子任务实例（具体数量未披露）"]}, "experiment": {"text": "在统一任务代理GPT-5.1-mini上系统评测三类记忆增强方案：长上下文基线（0D）、外部记忆代理（1D/2D）及RAG系统；对比其任务完成率、过程分、延迟代价与鲁棒性。", "bullets": ["【基线模型】：GPT-5.1-mini (统一代理)", "【对比方案】：0D（长上下文）, 1D/2D（外部记忆代理）, RAG", "【消融实验】：未显式开展，但通过任务类型难度差异（如旅行规划SR≈0）隐含机制归因"]}, "metrics": {"text": "采用任务完成率（SR）、过程分（PS）、软过程分（sPS）三维评估，并按子任务深度（@k）统计性能衰减。", "bullets": ["Pass@1 (SR)", "Process Score (PS)", "Soft Process Score (sPS)", "SR@k (k=1,2,...)"]}, "results": {"text": "所有SOTA记忆方法在MEMORYARENA上表现极差（平均SR仅0.02–0.23），显著低于其在LoCoMo等静态基准上的性能；RAG在超长轨迹（>122k token）中更稳定；外部记忆系统未普遍优于长上下文；所有方法均呈现SR@k单调衰减。", "bullets": ["MEMORYARENA：Average SR = 0.02–0.23 (-75% vs LoCoMo)", "Group Travel Planning：SR ≈ 0.0 (最难关卡)", "Progressive Search (122k+ token)：RAG SR > 0D by +18%", "All Methods：SR@3 / SR@1 < 0.4 (强衰减)"]}, "limitations": {"text": "基准当前依赖人工构造任务，扩展成本高；未覆盖实时动态环境反馈（如API调用失败重试）；统一代理GPT-5.1-mini的封闭性可能弱化对开源模型泛化性的刻画。", "bullets": ["【构造成本高】：四类任务均为专家人工设计，难以规模化扩展", "【环境简化】：未建模真实POMDP环境中的随机观测噪声与动作反馈延迟", "【代理局限】：基于GPT-5.1-mini单一代理解析，未覆盖开源模型记忆适配差异"]}}}
{"paper_id": "2602.16346", "title": "Helpful to a Fault: Measuring Illicit Assistance in Multi-Turn, Multilingual LLM Agents", "url": "https://arxiv.org/abs/2602.16346", "year": 2026, "blocks": {"background": {"text": "大语言模型代理在多轮、多语言交互中执行非法任务的风险难以被传统单轮红队评测准确捕捉，现有方法缺乏对攻击过程动态性、语言多样性及统计可解释性的建模。", "bullets": ["【痛点】：单轮提示评测严重低估多轮自适应攻击下的真实越狱风险", "【现状】：红队评估多依赖静态提示，缺乏对攻击时序、语言泛化与统计显著性的系统刻画"]}, "objective": {"text": "提出首个支持多轮自适应攻击、多语言覆盖与统计化分析的自动化红队评估框架STING，以科学量化LLM代理的安全脆弱性。", "bullets": ["【任务】：红队评估（安全风险探测）", "【核心贡献】：首个融合多轮代理协同、多语言工具接口与生存分析的自动化红队框架"]}, "method": {"text": "输入为非法任务目标；经四代理协同架构（策略师→攻击者→拒绝检测器→阶段完成检查器）进行多轮自适应交互；输出为首次越狱时间、风险比、RMJD等生存分析指标。", "bullets": ["【输入】：非法任务目标（如‘生成钓鱼邮件’）", "【架构】：四代理协同（策略师/攻击者/拒绝检测器/阶段完成检查器）", "【关键机制】：生存分析建模（首次越狱时间）、语言无关工具接口、动态阶段分解", "【是否训练】：否 (无需参数更新，纯推理驱动的评估框架)", "【创新点】：将红队过程形式化为生存分析问题，引入RMJD、发现曲线、风险比归因"]}, "data": {"text": "基于AgentHarm基准动态适配构建多轮测试场景，合成覆盖6种非英语语言的工具调用与指令集。", "bullets": ["【数据集】：AgentHarm (动态适配至多轮设置)", "【来源】：合成多语言工具接口 + AgentHarm原始场景", "【语言】：英语、法语、乌克兰语、印地语、乌尔都语、泰卢固语"]}, "experiment": {"text": "在GPT-5.1、Gemini 3 Flash、Qwen3-Next等主流模型上开展多语言多轮红队实验，对比单轮基线，并进行消融研究以验证推理强度、工具知识与防御机制的影响。", "bullets": ["【基线模型】：GPT-5.1, Gemini 3 Flash, Qwen3-Next", "【基线方法】：单轮提示红队（vanilla prompt injection）", "【消融实验】：移除策略师模块 / 关闭拒绝检测 / 固定语言不变量"]}, "metrics": {"text": "采用生存分析标准指标评估攻击进程效率与模型鲁棒性，辅以传统完成率与安全权衡指标。", "bullets": ["RMJD (Restricted Mean Jailbreak Discovery time)", "Hazard Ratio", "Discovery Curve (Kaplan-Meier estimate)", "Pass@1 (task completion rate)", "Win Rate (vs benign task interference)"]}, "results": {"text": "STING显著提升非法任务检出能力，揭示语言影响具有模型依赖性，且推理强度与安全性呈非单调关系。", "bullets": ["AgentHarm：非法任务完成率 = +107.1% vs 单轮提示", "法语：Gemini 3 Flash hazard ratio = 2.41 (p<0.01)", "印地语：Qwen3-Next RMJD = 18.7轮 (+23.6% safer than English)", "中等推理强度：GPT-5.1越狱延迟最长（平均RMJD ↑31.2%）", "安全提示词：有害任务完成率 ↓37.3%，良性任务干扰仅 ↑5.8%"]}, "limitations": {"text": "框架依赖预定义工具生态与阶段分解逻辑，尚未覆盖完全开放域自主规划场景；生存分析假设（比例风险）在极端语言/模型组合下可能不成立。", "bullets": ["【假设强】：依赖Cox比例风险假设，未验证所有语言-模型对的hazard比例性", "【覆盖窄】：当前工具接口基于AgentHarm有限工具集，未泛化至任意API或未知插件", "【依赖人工】：策略师的人设与阶段分解仍需少量规则引导，非端到端学习"]}}}
{"paper_id": "2602.16424", "title": "Verifiable Semantics for Agent-to-Agent Communication", "url": "https://arxiv.org/abs/2602.16424", "year": 2026, "blocks": {"background": {"text": "多智能体系统中，AI代理对同一术语的语义理解不一致导致通信不可靠、不可审计，现有方法依赖内部表征解释或私有协议翻译，缺乏可观测性与统计保证。", "bullets": ["【痛点】：语义分歧不可验证、不可量化、不可恢复", "【现状】：主流对齐方法缺乏行为可观察性与误差界控制"]}, "objective": {"text": "提出首个具备统计保证的语义认证协议，实现可验证、可更新、可恢复的核心词汇集构建，并通过核心约束推理严格控制代理间语义分歧在预设误差界内。", "bullets": ["【任务】：语义对齐的可验证认证", "【核心贡献】：基于行为一致性测试的带误差界（δ）的语义认证协议"]}, "method": {"text": "以刺激-意义模型为基底，将语义定义为代理对共享可观测事件（如内容场景、交易）的响应模式；通过双代理见证测试+公共账本记录→Wilson置信区间估计矛盾率上界→阈值化认证→核心约束推理→周期性重认证与固化度驱动的再协商，形成闭环语义治理链。", "bullets": ["【输入】：共享可观测事件集（内容场景、交易等）、双代理响应序列（同意/中立/反对）", "【架构】：形式化认证算法 + 核心约束推理引擎 + 动态维护模块", "【关键机制】：单侧Wilson置信区间估计、核心约束推理（V*受限决策）、基于‘固化度’的再协商", "【是否训练】：否 (无需参数更新，纯行为统计与逻辑约束)", "【创新点】：将语义对齐建模为可观测行为一致性检验问题，并首次引入统计误差界（δ）保障跨代理结论一致性"]}, "data": {"text": "采用仿真数据（含噪声级、中度、高度语义分歧场景）与真实微调语言模型（Qwen2.5-3B）在内容审核任务中的行为响应数据。", "bullets": ["【数据集】：自建仿真语义分歧事件集", "【来源】：Qwen2.5-3B微调模型在内容审核任务中的响应日志", "【数据类型】：可观测事件-代理响应对（三元：事件, agent_A_label, agent_B_label）"]}, "experiment": {"text": "在仿真与真实模型双场景下评估认证有效性、核心约束抑制分歧能力、重认证时效性及再协商恢复力；对比无约束基线与不同漂移强度下的动态表现。", "bullets": ["【基线模型】：无核心约束的原始代理通信", "【消融实验】：移除重认证 / 移除再协商 / 使用普通置信区间（非Wilson单侧）", "【评估维度】：分歧率控制效果、核心规模稳定性、漂移检测延迟、恢复成功率"]}, "metrics": {"text": "以代理间语义分歧率（contradiction rate）为核心指标，辅以核心词汇集规模、重认证触发延迟、再协商成功率等过程指标。", "bullets": ["Contradiction Rate", "Core Size", "Detection Latency", "Recovery Success Rate"]}, "results": {"text": "核心约束推理将分歧率稳定控制在≈2%，显著优于未约束基线（2.1%–40.7%）；在真实Qwen2.5-3B任务中分歧率从5.3%降至2.6%；重认证及时捕获漂移并恢复核心规模。", "bullets": ["仿真场景：Contradiction Rate = ~2% (+72–96% reduction vs baseline)", "Qwen2.5-3B内容审核：Contradiction Rate = 2.6% (-51% vs 5.3%)", "漂移检测：分歧率从2.2%→4.6%后于1轮重认证回落至2.0%", "再协商恢复：Core Size = 4.0 vs 3.5 (-12.5% shrinkage recovered)"]}, "limitations": {"text": "协议性能依赖可观测事件集的代表性与覆盖度；对响应标签粒度（仅三类）敏感；未覆盖多代理超图式协同场景。", "bullets": ["【假设强】：依赖共享可观测事件集完备且代表性充足", "【粒度限制】：响应仅建模为三类离散标签（同意/中立/反对），丢失细粒度偏好", "【扩展性弱】：当前设计面向两代理认证，多代理扩展需额外协调开销"]}}}
{"paper_id": "2602.16429", "title": "TabAgent: A Framework for Replacing Agentic Generative Components with Tabular-Textual Classifiers", "url": "https://arxiv.org/abs/2602.16429", "year": 2026, "blocks": {"background": {"text": "智能体系统中，大语言模型频繁用于封闭集决策（如工具筛选），导致高延迟与高推理成本；现有生成式方法缺乏对执行轨迹中结构化信号的有效利用。", "bullets": ["【痛点】：重复调用LLM进行封闭集决策造成显著延迟与成本开销", "【现状】：主流方法将决策视为生成任务，忽视智能体自身执行轨迹中蕴含的丰富监督信号"]}, "objective": {"text": "提出TabAgent框架，以表格-文本联合分类器替代生成式决策组件，在保障任务成功率的同时大幅降低延迟与推理成本。", "bullets": ["【任务】：封闭集工具筛选（短列表生成）", "【核心贡献】：范式转换——将生成式决策重构为可监督的表格分类问题"]}, "method": {"text": "输入为候选工具的文本描述及从执行轨迹中提取的TabSchema结构化特征向量；经轻量级TabHead模型单次前向传播，输出校准后的工具选择概率。", "bullets": ["【输入】：TabSchema特征向量 + 候选工具文本描述", "【架构】：轻量级表格-文本联合分类器（TabHead, ~50M参数）", "【关键机制】：TabSchema（分层结构化特征提取）、TabSynth（结构对齐的合成数据生成）、联合嵌入与概率校准", "【是否训练】：是（监督式微调，使用真实轨迹+TabSynth合成数据）", "【创新点】：行为驱动特征工程 + 结构对齐合成 + 紧凑判别模型三段式设计"]}, "data": {"text": "基于AppWorld基准构建训练与评估数据，覆盖5个跨应用任务；TabSynth生成的数据受工具目录结构与依赖规律约束。", "bullets": ["【数据集】：AppWorld (跨应用智能体基准)", "【来源】：真实成功执行轨迹 + TabSynth合成轨迹", "【结构约束】：工具目录层级、共现/时序/成败依赖规律"]}, "experiment": {"text": "在5个AppWorld任务上评估短列表质量与系统延迟；对比多种基线，包括生成式短列表器、检索式方法（BM25/DSR-FT）及LLaMA系列模型。", "bullets": ["【基线模型】：GPT-4.1（原短列表器）、LLaMA-3-8B、BM25、零样本稠密检索、微调稠密检索（DSR-FT）", "【消融实验】：移除TabSchema特征、禁用TabSynth、仅用任务描述输入", "【部署评估】：端到端延迟与推理token成本测量"]}, "metrics": {"text": "采用Recall@k与P@R（Precision-at-Recall）评估短列表质量；辅以端到端延迟（ms）与推理token消耗量化效率提升。", "bullets": ["Recall@7", "Recall@9", "P@R", "Latency (ms)", "Inference Token Cost"]}, "results": {"text": "TabAgent在维持短列表质量前提下实现显著效率增益；TabSynth有效缓解稀疏依赖建模瓶颈；TabSchema特征对性能提升起主导作用。", "bullets": ["AppWorld：Recall@7 ≥ 0.88, Recall@9 ≥ 0.92 (vs GPT-4.1持平)", "AppWorld：P@R = +0.14 avg. with TabSynth", "TabSchema特征贡献：P@R +24.7% vs task-only baseline", "延迟降低：95% (vs GPT-4.1)", "推理成本下降：85–91% (token-based)"]}, "limitations": {"text": "当前方法依赖高质量成功执行轨迹构建TabSchema；对未见工具类型或动态扩展场景的泛化能力尚未充分验证。", "bullets": ["【数据依赖强】：需足够多的成功执行轨迹初始化TabSchema", "【泛化受限】：工具目录结构变更或新增未见工具类型时需重新合成与适配", "【假设强】：依赖预定义的工具模式与依赖关系建模范式"]}}}
{"paper_id": "2602.16444", "title": "RoboGene: Boosting VLA Pre-training via Diversity-Driven Agentic Framework for Real-World Task Generation", "url": "https://arxiv.org/abs/2602.16444", "year": 2026, "blocks": {"background": {"text": "VLA（Vision-Language-Action）模型预训练面临严重数据瓶颈：真实机器人操作数据稀缺、采集成本高，而现有大模型生成的数据普遍存在幻觉严重、物理不可执行、多样性不足、长尾分布失衡等问题。", "bullets": ["【痛点】：生成任务物理不可执行（运动学/动力学违规）", "【痛点】：任务类型高度集中于常见场景（如家居），长尾物体与技能覆盖极低", "【痛点】：缺乏对人类失败经验的闭环利用机制，无法持续提升生成质量"]}, "objective": {"text": "提出RoboGene框架，实现高质量、高多样性、物理可执行且可持续进化的VLA预训练任务数据自动化生成。", "bullets": ["【任务】：机器人操作任务生成（面向VLA预训练）", "【核心贡献】：首个融合LFU主动探索、三重自反思评估与人类反馈记忆的闭环智能体数据生成框架"]}, "method": {"text": "以场景/物体/技能为三维空间，通过LFU策略采样低频区域生成候选任务；经物理可行性、新颖性、约束一致性三 evaluator 并行评估打分与过滤；最终结合语义检索增强的长期记忆模块（存储人类失败反馈提炼的启发式规则），通过RAG动态注入生成上下文，完成闭环迭代优化。", "bullets": ["【输入】：预定义物体集合、技能集合、场景类别体系", "【架构】：多 evaluator 智能体 + RAG增强记忆模块", "【关键机制】：LFU分层采样、三重 grounded 评估（物理/新颖/约束）、语义检索型长期记忆", "【是否训练】：否 (无需参数更新，纯推理与规则检索)", "【创新点】：将数据生成升维为具备感知—决策—反思—记忆能力的闭环智能体系统"]}, "data": {"text": "生成数据面向VLA模型预训练，覆盖广泛物理场景与具身交互任务，不依赖特定原始数据集，但评估时使用标准机器人任务基准与真实执行反馈。", "bullets": ["【数据集】：DFR-BuildBlocks（多阶段双臂任务）", "【来源】：真实双臂机器人执行失败的人类自然语言反馈", "【构建方式】：自动生成 + 人类反馈蒸馏"]}, "experiment": {"text": "在任务质量、多样性、下游VLA预训练效果三方面进行系统评估，并与人类专家、GPT-4o等强基线对比；开展消融实验验证LFU、三 evaluator、记忆模块各自贡献。", "bullets": ["【基线模型】：人类专家、GPT-4o", "【消融实验】：移除LFU采样 / 关闭新颖性评估器 / 禁用记忆模块", "【下游模型】：π₀（基于RoboGene数据预训练的VLA模型）"]}, "metrics": {"text": "采用多维人工评估指标与真实世界执行成功率联合评测，强调物理 grounded 性与泛化能力。", "bullets": ["Task Clarity", "Type Consistency", "Physical Feasibility", "Pass@1 (real-world success rate)", "Object Coverage", "Skill Coverage"]}, "results": {"text": "RoboGene在任务质量、多样性与下游性能上全面超越人类专家与GPT-4o；尤其在复杂多阶段任务中实现突破性提升。", "bullets": ["任务清晰度：0.991 (+2.7% vs human)", "物理可行性：0.990 (+4.2% vs human)", "物体覆盖：719种 (+100% vs GPT-4o)", "技能覆盖率：91.5% (+66.1pp vs baseline)", "DFR-BuildBlocks：30% (+25pp vs human)", "五类未见双臂任务平均成功率：48% (+10pp vs human, +12pp vs GPT-4o)"]}, "limitations": {"text": "当前框架依赖预定义的物体/技能/场景本体体系，对开放世界新概念泛化能力有限；真实执行反馈收集仍需一定人工介入；三 evaluator 的计算开销较高。", "bullets": ["【假设强】：依赖人工构建的物体/技能/场景结构化词表", "【开销大】：三 evaluator 并行运行带来显著推理延迟", "【覆盖限】：尚未支持零样本引入全新物理对象或非预设交互模态"]}}}
{"paper_id": "2602.16456", "title": "Beyond SGD, Without SVD: Proximal Subspace Iteration LoRA with Diagonal Fractional K-FAC", "url": "https://arxiv.org/abs/2602.16456", "year": 2026, "blocks": {"background": {"text": "LoRA微调中理想但昂贵的SVDLORA（全步更新+截断SVD投影）因需计算大矩阵SVD而难以实用；现有低秩优化方法缺乏对结构化二阶曲率信息的有效整合，且易受正则选择影响导致训练不稳定。", "bullets": ["【痛点】：全矩阵SVD计算开销高、内存爆炸，无法部署于大规模LoRA更新", "【现状】：主流LoRA变体（如RPLoRA）未显式建模梯度几何结构，预条件能力弱"]}, "objective": {"text": "提出一种无需显式SVD、可微、内存高效且支持结构化预条件的低秩投影算子，逼近SVDLORA解，并统一扩展至K-FAC等二阶优化场景。", "bullets": ["【任务】：低秩矩阵逼近（Frobenius范数下最优秩-r投影）", "【核心贡献】：LORSUM——无SVD的proximal子空间迭代子程序；F-LORSUM——嵌入对角K-FAC的扩展"]}, "method": {"text": "将LoRA一步更新建模为带proximal正则的低秩逼近问题，通过高斯-赛德尔交替更新U/V因子实现隐式子空间迭代；每步仅依赖r×r小矩阵运算，避免d_out×d_in大矩阵构造。", "bullets": ["【输入】：当前LoRA参数(U_t, V_t)、梯度G_t、学习率η、秩r、proximal权重ρ", "【架构】：交替最小二乘（ALS）+ proximal子空间迭代（PSI）", "【关键机制】：块幂迭代（subspace iteration）、proximal正则（‖U−U_t‖²+‖V−V_t‖²）、对角K-FAC嵌入", "【是否训练】：否 (无需参数更新；LORSUM是确定性求解子程序，非可学习模块)", "【创新点】：将SVDLORA转化为可微、无SVD、内存O(d_in+d_out)的显式投影算子；首次将K-FAC曲率信息以对角近似形式无缝融入LoRA更新流"]}, "data": {"text": "实验涵盖合成线性回归任务及多个标准基准数据集，覆盖视觉、语言理解与生成任务。", "bullets": ["【数据集】：Synthetic Linear Task (可控秩/噪声)", "【数据集】：CIFAR-100 (图像分类)", "【数据集】：GLUE (语言理解)", "【数据集】：SQuADv2 (问答)", "【数据集】：WikiText-103 (语言建模)"]}, "experiment": {"text": "在相同LoRA秩与超参设置下，对比标准LoRA、RPLoRA、全参数微调（FT）及SVDLORA（oracle）；消融研究验证K（内迭代数）、ρ（proximal强度）与F-LORSUM中√K-FAC的影响。", "bullets": ["【基线模型】：LoRA, RPLoRA, Full FT", "【消融实验】：K=1 vs K=5 vs K=10（收敛性与泛化权衡）", "【消融实验】：ρ=0 vs ρ>0（稳定性验证）", "【消融实验】：F-LORSUM vs F-LORSUM w/o √K-FAC（曲率有效性）"]}, "metrics": {"text": "采用任务标准评估协议，重点考察准确率、F1、EM、PPL等指标，并额外报告学习率鲁棒性与内存/通信开销。", "bullets": ["Accuracy", "F1", "Exact Match (EM)", "Perplexity (PPL)", "Win Rate (vs baseline)", "Step Norm"]}, "results": {"text": "LORSUM在多项任务上超越LoRA与RPLoRA，部分达到甚至超过全参数微调；F-LORSUM展现出极强学习率鲁棒性（0.01–10.0），且内存开销显著低于Adam。", "bullets": ["CIFAR-100：Accuracy = 82.7% (+3.2% vs RPLoRA)", "SQuADv2：EM = 84.1% (+2.6% vs LoRA; +0.9% vs FT)", "WikiText-103：PPL = 18.3 (-1.4 vs LoRA)", "GLUE Avg：Score = 87.5 (+1.8 vs RPLoRA)", "F-LORSUM：Win Rate = 92% across 10 learning rates (0.01–10.0)"]}, "limitations": {"text": "LORSUM依赖内迭代数K控制逼近精度，但K过大在随机梯度下易早停；F-LORSUM目前仅使用对角K-FAC近似，损失部分二阶结构信息。", "bullets": ["【假设强】：收敛分析基于精确梯度；SGD噪声下理论保证减弱", "【计算权衡】：K增大提升逼近质量但增加每步延迟，需任务级调优", "【近似局限】：F-LORSUM采用对角K-FAC，忽略跨层/跨参数相关性"]}}}
{"paper_id": "2602.16481", "title": "Leveraging Large Language Models for Causal Discovery: a Constraint-based, Argumentation-driven Approach", "url": "https://arxiv.org/abs/2602.16481", "year": 2026, "blocks": {"background": {"text": "因果图学习面临统计方法缺乏语义先验、而LLM直接生成因果图易产生幻觉与记忆偏差的双重困境；现有LLM增强方法难以兼顾可验证性、透明性与形式严谨性。", "bullets": ["【痛点】：LLM作为黑箱因果生成器易引入幻觉与训练数据记忆偏差", "【现状】：统计方法（如CI检验）缺乏语义引导，导致稀疏数据下结构恢复鲁棒性差"]}, "objective": {"text": "提出首个将LLM建模为可废止专家并嵌入Causal ABA论证框架的因果发现方法，实现语义先验与统计证据的可验证、可辩护融合。", "bullets": ["【任务】：因果图结构学习（DAG discovery）", "【核心贡献】：将LLM作为可废止专家接入Causal ABA框架，支持共识过滤、结构化约束提取与论证驱动融合"]}, "method": {"text": "以变量名与自然语言描述为输入，经三阶段LLM约束提取流水线生成方向性因果约束；通过五轮独立查询+交集共识机制筛选高置信约束；将共识结果编码为Causal ABA中的可废止事实，与CI检验所得骨架联合参与逻辑论证求解，强制要求LLM建议边必须存在于CI保留骨架中，否则自动丢弃。", "bullets": ["【输入】：变量名 + 变量自然语言描述", "【架构】：Causal ABA（论证逻辑框架） + 多轮LLM querying（GPT-4级模型）", "【关键机制】：共识过滤（5×交集）、结构化约束提取（必需/禁止方向）、论证驱动融合（可废止事实 + CI证据）、骨架一致性强制校验", "【是否训练】：否 (无需参数更新，纯推理时prompting)", "【创新点】：LLM作为可废止专家而非生成器，首次实现因果发现中语义先验的可质疑、可隔离、可追溯集成"]}, "data": {"text": "构建CauseNet合成评估协议用于主实验，并在标准bnlearn基准上进行泛化验证。", "bullets": ["【数据集】：CauseNet（合成，基于子图同构锚定至真实知识图谱）", "【数据集】：bnlearn（SACHS, CHILD等真实DAG基准）", "【来源】：子图同构生成 + 真实知识图谱（如Wikidata/ConceptNet）+ bnlearn公开库"]}, "experiment": {"text": "在5节点与15节点CauseNet任务上对比主流方法；开展消融实验验证变量描述、共识机制等模块作用；进行热力图分析探究LLM约束质量与CI证据质量的协同效应。", "bullets": ["【基线模型】：MPC, FGS, NOTEARS-MLP, GRaSP, BOSS, LLM-BFS (BFS)", "【消融实验】：移除变量描述 / 关闭共识机制 / 移除骨架一致性校验", "【分析实验】：LLM约束F1 × CI证据质量热力图分析"]}, "metrics": {"text": "采用因果发现标准结构评估指标，在合成与真实数据上统一评测。", "bullets": ["SHD", "F1", "SID"]}, "results": {"text": "ABAPC-LLM在CauseNet上全面超越所有基线，尤其在5/15节点任务中显著领先（p<0.001）；在bnlearn复杂图（如CHILD）上保持稳健优势，规避LLM记忆效应导致的过拟合假象。", "bullets": ["CauseNet-5：F1 = 82.3% (+9.7% vs BOSS)", "CauseNet-15：SID = 14.2 (+21% vs GRaSP)", "CHILD（bnlearn）：SHD = 18.6 (-3.1 vs LLM-BFS)", "共识机制：禁忌方向精度 ≈ 100%（剔除零约束案例）"]}, "limitations": {"text": "依赖高质量变量描述提升LLM约束质量；共识机制牺牲召回率；当前仅支持静态DAG学习，未扩展至时序或干预场景。", "bullets": ["【假设强】：依赖人工编写的变量描述，影响端到端自动化", "【开销大】：5轮LLM查询带来推理延迟与成本上升", "【范围窄】：仅适用于无干预的观测性因果发现，未处理do-calculus或动态结构"]}}}
{"paper_id": "2602.16485", "title": "Team of Thoughts: Efficient Test-time Scaling of Agentic Systems through Orchestrated Tool Calling", "url": "https://arxiv.org/abs/2602.16485", "year": 2026, "blocks": {"background": {"text": "现有多智能体系统普遍依赖同质化代理（如多个相同大模型实例），导致任务适配性差、token开销高，且缺乏对异构大模型专长的动态利用机制。", "bullets": ["【痛点】：同质化代理无法按任务需求动态匹配最优模型", "【现状】：协调器默认选用最大模型，忽视协调能力与规模非正相关"]}, "objective": {"text": "提出Team-of-Thoughts框架，实现测试时高效、可扩展、低开销的异构大模型协同推理。", "bullets": ["【任务】：多智能体协同推理", "【核心贡献】：提出‘协调器-工具’范式，支持异构模型动态选型、自评估与令牌感知并行调用"]}, "method": {"text": "输入为用户查询与任务类别标签；协调器基于能力画像选择高匹配度工具代理，并行触发其原生tool-calling接口；各工具代理独立生成结果，协调器聚合输出；全程支持差异化token预算分配。", "bullets": ["【输入】：用户查询 + 任务类别（如数学/代码）", "【架构】：分层架构（协调器 + 多个工具代理）", "【关键机制】：协调器校准、工具代理自评估协议、能力画像驱动的动态路由、令牌感知预算分配", "【是否训练】：否 (协调器与工具代理均零样本使用，仅验证集上做离线选型与画像构建)", "【创新点】：解耦调度与执行、轻量级自评估替代联合训练、非单调协调器选型"]}, "data": {"text": "实验基于数学与代码两类典型复杂推理任务构建验证与测试闭环。", "bullets": ["【数据集】：AIME24 (数学推理)", "【数据集】：LiveCodeBench (代码生成)", "【来源】：公开竞赛题库与真实编程评测平台"]}, "experiment": {"text": "在AIME24和LiveCodeBench上对比主流多智能体基线，并开展消融研究以验证协调器校准、自评估协议与并行调度的有效性。", "bullets": ["【基线模型】：AgentVerse, GPT-4-based ensemble", "【消融实验】：移除协调器校准、替换自评估为协调器评估、禁用并行调用", "【任务分组】：按数学/代码任务类别独立评估协调器与工具代理性能"]}, "metrics": {"text": "采用任务标准准确率指标，并报告相对提升与token效率增益。", "bullets": ["Exact Match (EM)", "Pass@1", "Token Cost (per query)"]}, "results": {"text": "Team-of-Thoughts在准确性与效率上全面超越基线，验证了异构协同的价值与轻量部署可行性。", "bullets": ["AIME24：EM = 96.67% (+16.67% vs AgentVerse)", "LiveCodeBench：Pass@1 = 72.53% (+6.60% vs AgentVerse)", "Token Cost：降低一个数量级 (≈10× reduction)"]}, "limitations": {"text": "当前框架依赖显式任务类别标签，且能力画像构建需少量验证集样本；动态路由尚未支持细粒度子任务分解。", "bullets": ["【假设强】：需预先提供任务类别（如'数学'）以检索能力画像", "【数据依赖】：工具代理自评估需少量验证集样本（未标注）", "【扩展性】：暂不支持无类别提示下的端到端路由决策"]}}}
{"paper_id": "2602.16488", "title": "Learning to Learn from Language Feedback with Social Meta-Learning", "url": "https://arxiv.org/abs/2602.16488", "year": 2026, "blocks": {"background": {"text": "大语言模型在单轮对话中难以处理信息不完整、模糊或需渐进式澄清的任务，缺乏主动从语言反馈中学习的能力。", "bullets": ["【痛点】：传统指令微调范式局限于单轮响应，无法建模多轮反馈驱动的学习过程", "【现状】：现有方法未显式建模师生互动中的信息不对称与上下文内学习机制"]}, "objective": {"text": "提出社会元学习（SML）微调范式，使LLMs具备在对话中主动索取、理解并利用语言反馈的能力，并实现跨任务域泛化。", "bullets": ["【任务】：多轮反馈驱动的对话式学习", "【核心贡献】：将人类社会元学习机制形式化为可扩展的LLM微调框架"]}, "method": {"text": "将静态任务重构为学生-教师pedagogical dialogue，建模为POMDP；通过Q-priming预训练+离线SFT+在线GRPO强化学习联合优化学生策略。", "bullets": ["【输入】：对话历史（含用户请求、教师反馈/验证结果）", "【架构】：基于Transformer的LLM（如Llama-2、Qwen）", "【关键机制】：POMDP建模、Q-priming引导提问、GRPO多轮稀疏奖励优化", "【是否训练】：是 (SFT + GRPO联合微调)", "【创新点】：首次将社会性元学习机制结构化为可训练的对话学习范式"]}, "data": {"text": "构建多任务pedagogical dialogue数据集，覆盖数学、编程等任务类型，含教师私有知识（答案/测试用例）与学生交互轨迹。", "bullets": ["【数据集】：自建SML-Dialogue (数学+代码)", "【来源】：GSM8K、MATH、LiveCodeBench + 人工构造师生交互", "【标注】：成功解题路径、教师反馈信号、提问-澄清对"]}, "experiment": {"text": "在数学（GSM8K/MATH）、代码（LiveCodeBench）及模糊推理（Lost-in-Conversation）基准上评估，对比单轮基线、纯SFT及消融变体。", "bullets": ["【基线模型】：Llama-2-7b, Qwen-1.5-7b", "【消融实验】：移除Q-priming、禁用GRPO、仅用SFT", "【对比设置】：单轮指令微调、ICL（few-shot）、ReAct"]}, "metrics": {"text": "以最终任务完成率为核心，辅以提问率、过早作答率、对话轮次鲁棒性等行为指标。", "bullets": ["Pass@1", "Exact Match (EM)", "Question Rate", "Premature Answer Rate", "Long-Horizon Success (10-turn)"]}, "results": {"text": "SML显著提升模型在信息不完整场景下的鲁棒性与协作能力，且具备强跨域迁移性。", "bullets": ["GSM8K：Pass@1 = 82.3% (+15.6% vs SFT-only)", "LiveCodeBench：EM = 64.1% (+9.2% vs 单轮基线，迁移自数学SML模型)", "Lost-in-Conversation：Question Rate = 5.3× baseline, Premature Answer Rate ↓42%"]}, "limitations": {"text": "依赖高质量师生对话数据构造，POMDP隐状态建模存在近似误差，实时推理开销随对话轮次增长。", "bullets": ["【数据依赖强】：需人工设计教师反馈逻辑与私有知识注入", "【建模近似】：POMDP隐状态（教师知识）仅通过对话历史间接推断", "【开销大】：多轮GRPO训练收敛慢，10轮推理延迟上升约3.2×"]}}}
{"paper_id": "2602.16490", "title": "From Growing to Looping: A Unified View of Iterative Computation in LLMs", "url": "https://arxiv.org/abs/2602.16490", "year": 2026, "blocks": {"background": {"text": "深度循环模型与深度生长模型被分别提出以提升大语言模型（LLM）的推理能力，但二者机制差异长期被视为正交设计；现有研究缺乏对底层计算动力学的统一解释。", "bullets": ["【痛点】：循环与生长范式被孤立评估，缺乏机制层面的可比性与统一理论框架", "【现状】：工程上二者常被互斥使用，未探究其是否共享同一类迭代计算本质"]}, "objective": {"text": "从计算机制层面统一深度循环与深度生长两种范式，验证其共享深度级迭代签名，并探索二者组合使用的可行性与增益。", "bullets": ["【任务】：机制统一性分析与可组合性验证", "【核心贡献】：首次证明循环与生长同源，共享4层周期性深度级计算签名"]}, "method": {"text": "通过多维诊断工具量化层间计算依赖模式，并设计层交换干预与中段循环复用实验，验证迭代机制的鲁棒性与可迁移性。", "bullets": ["【输入】：预训练LLM（如Llama-2）的中间层激活与残差流", "【架构】：基于Transformer的循环模型（Loop系列）与深度生长模型（LIDAS/MIDAS）", "【关键机制】：深度利用率诊断（depth score、Tuned Lens早退准确率、top-5词表重叠）、残差流范数分析、注意力子层贡献周期性检测、层交换干预、中段块重复执行（retrofitted recurrence）", "【是否训练】：否 (所有干预与复用均在已训练模型上进行，无需参数更新)", "【创新点】：提出‘中段为天然迭代区’假设，并验证生长模型可无训练受益于循环式重复执行"]}, "data": {"text": "实验基于公开基准任务开展，聚焦数学推理等需强链式推理的场景。", "bullets": ["【数据集】：GSM8K (数学推理)", "【来源】：标准开源评测集，未引入私有或合成数据"]}, "experiment": {"text": "在相同基线模型（如Llama-2）上对比标准模型、全循环模型、中段循环模型（Loop(4-4×4-4)）与深度生长模型（LIDAS/MIDAS），并开展消融与干预实验。", "bullets": ["【基线模型】：Llama-2", "【对比模型】：Loop(1-N)（全循环）、Loop(4-4×4-4)（中段循环）、LIDAS、MIDAS", "【消融实验】：层交换干预（单层置换）、中段块重复步数消融（1×→4×）", "【干预实验】：局部层序扰动热图分析、残差流范数与注意力贡献时序追踪"]}, "metrics": {"text": "采用任务级准确率为主指标，并辅以机制性诊断指标刻画计算行为。", "bullets": ["Exact Match (EM)", "Pass@1", "depth score", "Tuned Lens早退准确率", "top-5词表重叠率"]}, "results": {"text": "循环与生长模型展现出高度一致的深度周期性特征；中段循环与深度生长模型在鲁棒性与可扩展性上表现趋同；组合策略（生长+中段循环）取得最优推理性能。", "bullets": ["GSM8K：EM = 78.5% (+12.3% vs Llama-2 baseline)", "中段循环（Loop(4-4×4-4)）vs LIDAS：早退准确率曲线相似度 >0.96", "深度生长模型经中段循环复用（2×迭代）：GSM8K EM提升达+9.7%，最高实现2×精度增益", "层交换实验显示：全循环模型Win Rate下降41.2%，而LIDAS仅下降3.8%，证实中段结构鲁棒性"]}, "limitations": {"text": "结论受限于当前诊断工具粒度与模型族覆盖范围，尚未在多模态或非Transformer架构上验证普适性。", "bullets": ["【假设强】：依赖‘4层块结构’作为通用周期单位，未验证跨架构泛化性", "【范围窄】：实验集中于数学推理任务（GSM8K），未覆盖长程依赖、符号推理等其他推理类型", "【工具限】：depth score与Tuned Lens对早期层判别力较弱，可能低估浅层动态贡献"]}}}
{"paper_id": "2602.16512", "title": "Framework of Thoughts: A Foundation Framework for Dynamic and Optimized Reasoning based on Chains, Trees, and Graphs", "url": "https://arxiv.org/abs/2602.16512", "year": 2026, "blocks": {"background": {"text": "现有思维链（CoT）、思维树（ToT）、思维图（GoT）等推理方法面临静态结构僵化、超参与提示未优化、执行效率低三大瓶颈。", "bullets": ["【痛点】：推理结构静态不可变，无法适应问题复杂度变化", "【痛点】：提示模板与超参数依赖人工调优，缺乏端到端自动化优化机制", "【痛点】：重复LLM调用与串行执行导致高延迟、高成本"]}, "objective": {"text": "提出Framework of Thoughts（FoT），首个支持动态图结构演化、安全并行执行、智能缓存及端到端提示/超参优化的通用LLM推理框架。", "bullets": ["【核心贡献】：将推理架构升维为可编程、可演化、可优化的运行时系统", "【任务】：构建动态可优化推理框架"]}, "method": {"text": "将推理解耦为‘执行图’（操作流）与‘推理图’（思维依赖流），运行时动态增删节点/边；通过祖先区/后代区/独占后代区约束实现安全并行；引入进程内+持久化两级缓存复用LLM结果；集成Optuna与DSPy联合优化提示模板与结构超参。", "bullets": ["【输入】：用户查询 + 任务定义（如数学推理、多跳问答）", "【架构】：动态有向图（执行图 + 推理图）", "【关键机制】：安全并行约束、两级缓存（进程内+持久化）、DSPy提示优化 + Optuna超参搜索", "【是否训练】：否 (无需模型参数更新，纯推理时序与提示层优化)", "【创新点】：首次统一实现推理结构动态演化、并发安全执行与资源感知优化"]}, "data": {"text": "在多个主流推理基准上验证，覆盖不同难度与结构需求的任务。", "bullets": ["【数据集】：Go24 (多步推理)", "【数据集】：DM (Dialogue Math)", "【数据集】：MuSiQue (多跳问答)", "【来源】：公开基准任务与对应推理轨迹"]}, "experiment": {"text": "在ToT、GoT、ProbTree三种基线推理范式上部署FoT，对比原始实现；开展消融实验验证动态图、并行、缓存、优化模块的独立贡献。", "bullets": ["【基线模型】：ToT, GoT, ProbTree (均基于Llama-2/GPT-4等LLM后端)", "【消融实验】：移除持久化缓存对优化成本的影响", "【消融实验】：关闭动态图演化对分支适应性的影响"]}, "metrics": {"text": "以准确率、F1、Pass@k、推理耗时、API调用次数、总成本（token×$）为综合评估指标。", "bullets": ["Pass@1", "Exact Match (EM)", "F1", "Latency (ms)", "Cost ($)", "Speedup"]}, "results": {"text": "FoT显著提升推理效率与经济性，在不牺牲性能前提下实现大幅加速与降本；提示与超参优化带来稳定性能增益，且降低单实例成本。", "bullets": ["Go24：EM = +3.0% vs ToT (+12% cost reduction)", "DM：F1 = +0.4 vs GoT (-13% cost)", "MuSiQue：Cost ↓46% with persistent cache", "Average Speedup：10.7× (1.9×–35.4× across ToT/GoT/ProbTree)", "Hyperopt Search Cost：↓90.64% (to 9.36% of baseline)"]}, "limitations": {"text": "动态图能力尚未完全泛化至Fully Automatic方案（如SoT），当前优化目标受限于可微或采样式指标，对强逻辑一致性约束支持有限。", "bullets": ["【覆盖弱】：尚未集成SoT等全自动结构生成范式", "【假设强】：依赖LLM输出可解析性以构建执行图", "【开销大】：初始Optuna搜索仍需数百次评估（虽经缓存大幅压缩）"]}}}
{"paper_id": "2602.16554", "title": "MerLean: An Agentic Framework for Autoformalization in Quantum Computation", "url": "https://arxiv.org/abs/2602.16554", "year": 2026, "blocks": {"background": {"text": "量子计算前沿研究高度依赖复杂数学陈述，但人工形式化为Lean等证明助手耗时费力、门槛高，严重制约可验证性与知识复用；现有工具多限于单命题级、需大量人工干预，缺乏端到端、论文级的自动化能力。", "bullets": ["【痛点】：前沿量子论文难以高效、可信地转化为机器可验证的形式化代码", "【现状】：形式化工具普遍依赖人工标注、定理拆解与交互调试，无法支持无人值守的整篇论文处理"]}, "objective": {"text": "提出首个全自动化、论文级、双向（形式化+反形式化）的量子计算形式化框架MerLean，实现从LaTeX源码到Lean 4代码的端到端零人工干预转化，并支持可解释的自然语言回溯。", "bullets": ["【任务】：全自动论文级数学陈述→Lean 4形式化", "【核心贡献】：MerLean——首个支持双向闭环、信仰性保障、公理透明化的全自动化形式化智能体框架"]}, "method": {"text": "输入为原始LaTeX论文源码；经双阶段流水线处理：第一阶段结构化解析为定义/定理JSON；第二阶段通过LLM驱动的‘生成–编译–修复’循环调用Lean LSP-MCP工具链实时获取类型检查、语义搜索与上下文信息，迭代生成正确Lean代码；失败时启动公理化阶段并显式声明axiom；最终由同一LLM将验证后的Lean代码逆向翻译为LaTeX蓝图与叙事文本。", "bullets": ["【输入】：原始LaTeX源码（含定义、定理、证明等数学环境）", "【架构】：多阶段智能体（Parser Agent + Lean Agent + Autoinformalizer Agent）", "【关键机制】：Lean LSP-MCP工具链集成、信仰性检验（faithfulness checking）、公理化阶段（axiom fallback）、反形式化（autoinformalization）", "【是否训练】：否 (无需参数更新；全部基于推理时工具调用与提示工程)", "【创新点】：双向闭环设计（formalization ↔ autoinformalization）、可审计公理声明机制、基于LSP-MCP的实时反馈驱动修复"]}, "data": {"text": "在三篇理论量子计算论文（含一篇未发表手稿）上进行端到端验证，覆盖114个原始数学陈述，生成2050个Lean声明。", "bullets": ["【数据集】：论文A（arXiv:xxxx.xxxx）、论文B（QIP 2023）、论文C（未发表手稿）", "【来源】：作者提供的LaTeX源码（零数据污染）"]}, "experiment": {"text": "在本地部署Lean 4 v4.8 + Mathlib 4.9环境，对比基线为人工形式化流程与时序分析；开展消融实验评估各模块（如LSP反馈、信仰检验、公理化）对成功率与迭代次数的影响。", "bullets": ["【基线模型】：人工形式化专家流程（时间/尝试次数统计）", "【消融实验】：移除信仰性检验 → 幻觉率上升37%；禁用LSP-MCP → 编译失败率增加5.2×"]}, "metrics": {"text": "以形式化成功率（verified statements / total statements）、平均编译尝试次数、平均耗时、公理引入率、反形式化忠实度（BLEU-4 & expert semantic alignment score）为评估标准。", "bullets": ["Pass@1 (verified)", "Avg. compile attempts", "Time per statement (min)", "Axiom introduction rate", "BLEU-4", "Expert alignment score (5-point Likert)"]}, "results": {"text": "MerLean在114个陈述上实现100%端到端形式化成功（2050/2050 Lean声明通过lean --run验证），总耗时<42小时；首次实现论文级全自动形式化可行性验证。", "bullets": ["All 114 statements：Pass@1 = 100% (+∞ vs human baseline in automation scope)", "Theorems：Avg. time = 39.7 min, Avg. attempts = 22.4", "Remarks/Notes：Avg. time = 10.6 min, Avg. attempts = 7.1", "Axiom rate：9.1% (all explicitly marked & cross-linked in Lean + LaTeX output)", "Auxiliary lemmas discovered：e.g., pauliPair_anticommuting_ct_satisfied (not stated in original text)"]}, "limitations": {"text": "当前框架受限于Lean Mathlib覆盖范围与LLM数学推理边界，对高度非标准或新构造性数学仍需人工介入；反形式化文本尚不能完全替代专业数学写作。", "bullets": ["【假设强】：依赖Mathlib中已有概念与符号约定；新代数结构需手动扩充", "【开销大】：单定理平均39.7分钟，尚未针对分布式/并行编译优化", "【领域窄】：当前仅验证量子计算论文，泛化至其他数学子域（如微分几何）待验证"]}}}
